{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddfcda0",
   "metadata": {},
   "source": [
    "# **√Årvores de Decis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e8a39",
   "metadata": {},
   "source": [
    "Nesse m√≥dulo come√ßaremos analisando oc conceitos b√°sicos que formulam uma √°rvore de decis√£o, sua filosofia e interpreta√ß√£o. Depois, vamos examinar o algoritmo CART usado pelo Scikit-Learn e explicar como utiliz√°-las para tarefas de regress√£o e Classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Lista de pacotes necess√°rios.\n",
    "# As chaves s√£o os NOMES PARA INSTALAR COM PIP.\n",
    "# Os valores s√£o os NOMES DOS M√ìDULOS PARA IMPORTAR (usado por importlib.import_module).\n",
    "# Se o nome para pip e o nome para importa√ß√£o forem iguais, o valor pode ser o mesmo da chave.\n",
    "pacotes_para_verificar_e_instalar = {\n",
    "    \"numpy\": \"numpy\",           # pip install numpy -> import numpy\n",
    "    \"matplotlib\": \"matplotlib\", # pip install matplotlib -> import matplotlib\n",
    "    \"pandas\": \"pandas\",         # pip install pandas -> import pandas\n",
    "    \"scikit-learn\": \"sklearn\",  # pip install scikit-learn -> import sklearn\n",
    "    \"IPython\": \"IPython\",       # pip install IPython -> import IPython\n",
    "    # Adicione outros pacotes aqui, seguindo o padr√£o: \"nome_pip\": \"nome_import\"\n",
    "    # Exemplo: \"requests\": \"requests\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para instalar pacotes\n",
    "def instalar_pacote(pacote_pip_nome):\n",
    "    \"\"\"\n",
    "    Instala um pacote Python usando pip.\n",
    "    pacote_pip_nome: o nome do pacote a ser passado para 'pip install'.\n",
    "    \"\"\"\n",
    "    print(f\"Instalando {pacote_pip_nome}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pacote_pip_nome])\n",
    "        print(f\"'{pacote_pip_nome}' instalado com sucesso.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Erro ao instalar '{pacote_pip_nome}': {e}\")\n",
    "        # √â uma boa pr√°tica sair do script se uma depend√™ncia essencial n√£o puder ser instalada.\n",
    "        sys.exit(1)\n",
    "\n",
    "# Verifica e instala os pacotes\n",
    "print(\"Verificando pacotes necess√°rios...\")\n",
    "for nome_pip, nome_modulo_import in pacotes_para_verificar_e_instalar.items():\n",
    "    try:\n",
    "        # Tenta importar o m√≥dulo. Se for bem-sucedido, o pacote j√° est√° instalado.\n",
    "        importlib.import_module(nome_modulo_import)\n",
    "        print(f\"O pacote '{nome_pip}' (m√≥dulo '{nome_modulo_import}') j√° est√° instalado.\")\n",
    "    except ImportError:\n",
    "        # Se ImportError ocorrer, o pacote n√£o est√° instalado e precisa ser.\n",
    "        instalar_pacote(nome_pip)\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(\"Todos os pacotes necess√°rios est√£o instalados e prontos para uso.\")\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db925f69",
   "metadata": {},
   "source": [
    "## **Bibliotecas usadas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbab63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # M√≥dulo para interagir com o sistema operacional (manipular diret√≥rios, arquivos, etc.)\n",
    "\n",
    "import numpy as np  # Biblioteca fundamental para computa√ß√£o num√©rica com arrays e fun√ß√µes matem√°ticas\n",
    "\n",
    "import matplotlib.pyplot as plt  # Biblioteca para cria√ß√£o de gr√°ficos e visualiza√ß√µes\n",
    "\n",
    "import pandas as pd  # Biblioteca para manipula√ß√£o e an√°lise de dados tabulares (DataFrames)\n",
    "\n",
    "import seaborn as sns  # Biblioteca para visualiza√ß√£o de dados baseada no matplotlib, com temas e paletas de cores aprimoradas\n",
    "\n",
    "from IPython.display import display, Markdown  # Para exibir objetos em Jupyter Notebooks de forma interativa\n",
    "\n",
    "from matplotlib.colors import ListedColormap  # Para criar mapas de cores personalizados em gr√°ficos\n",
    "\n",
    "from sklearn.datasets import load_iris  # Fun√ß√£o para carregar o dataset Iris, cl√°ssico para classifica√ß√£o\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate  # Para dividir o dataset em treino e teste e realizar valida√ß√£o cruzada\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold  # Para realizar valida√ß√£o cruzada estratificada, preservando propor√ß√µes das classes\n",
    "\n",
    "from sklearn.base import clone  # Para clonar modelos (√∫til em valida√ß√£o cruzada manual)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier  # Modelo de √Årvore de Decis√£o para tarefas de classifica√ß√£o\n",
    "\n",
    "from IPython.display import Image  # Para exibir imagens em ambientes interativos, como Jupyter Notebooks\n",
    "\n",
    "from sklearn.tree import plot_tree  # Fun√ß√£o para visualizar a √°rvore de decis√£o graficamente\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor  # Modelo de √Årvore de Decis√£o para tarefas de regress√£o\n",
    "\n",
    "from sklearn import datasets  # Subm√≥dulo para carregar diversos datasets de exemplo do scikit-learn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error  # M√©tricas para avaliar desempenho de modelos de classifica√ß√£o e regress√£o\n",
    "\n",
    "from sklearn import tree  # Subm√≥dulo geral que cont√©m fun√ß√µes e classes relacionadas a √°rvores de decis√£o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22f512",
   "metadata": {},
   "source": [
    "## Treinando e Visualizando uma √Årvore de Decis√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8334154a",
   "metadata": {},
   "source": [
    "### O Algor√≠tmo de Treinamento **CART**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62dd0db",
   "metadata": {},
   "source": [
    "O **Scikit-Learn** utiliza o algoritmo **CART (Classification and Regression Tree)** para treinar **√Årvores de Decis√£o**, processo tamb√©m conhecido como \"crescimento\" das √°rvores. O funcionamento do algoritmo se baseia, inicialmente, na divis√£o do **conjunto de treinamento** em dois subconjuntos, utilizando para isso uma √∫nica **feature** (denotada como `k`) e um determinado **limiar** (`t`), por exemplo: ‚Äúcomprimento da p√©tala ‚â§ 2.45 cm‚Äù.\n",
    "\n",
    "Mas como o algoritmo escolhe a melhor combina√ß√£o entre `k` e `t`? Ele realiza uma busca exaustiva por todas as poss√≠veis combina√ß√µes, selecionando aquela que produz os subconjuntos mais **puros**, ou seja, com menor mistura de classes. A pureza desses subconjuntos √© ponderada pelo seu tamanho, garantindo que subconjuntos maiores tenham maior influ√™ncia na decis√£o. A **fun√ß√£o de custo** que o CART tenta minimizar √© expressa pela seguinte equa√ß√£o:\n",
    "\n",
    "$$\n",
    "J(k, t_k) = \\dfrac{m_{esq}}{m}G_{esq} + \\dfrac{m_{dir}}{m}G_{dir}\n",
    "$$\n",
    "\n",
    "\n",
    "onde:\n",
    "\n",
    "- `G_esq` e `G_dir` s√£o as medidas de **impureza** dos subconjuntos esquerdo e direito, respectivamente.\n",
    "- `m_esq` e `m_dir` representam o **n√∫mero de inst√¢ncias** nesses subconjuntos.\n",
    "- `m` √© o n√∫mero total de inst√¢ncias no conjunto antes da divis√£o.\n",
    "\n",
    "Ap√≥s encontrar o melhor par `(k, t)`, o algoritmo **divide** o conjunto de treinamento em dois subconjuntos. Em seguida, ele **repete** o mesmo processo recursivamente: tenta novamente encontrar a melhor divis√£o para cada subconjunto, e assim por diante, criando sucessivamente **sub-subconjuntos**. Esse processo recursivo continua at√© que seja atingida uma das seguintes **condi√ß√µes de parada**: \n",
    "\n",
    "#### ‚úÖ Hiperpar√¢metros importantes\n",
    "\n",
    "##### 1. `max_depth`\n",
    "\n",
    "- **Defini√ß√£o:**  \n",
    "Profundidade m√°xima que a √°rvore pode atingir.\n",
    "\n",
    "- **Papel:**  \n",
    "Limita o crescimento da √°rvore, prevenindo overfitting e reduzindo a complexidade do modelo.\n",
    "\n",
    "- **Valor padr√£o:** `None` (ou seja, cresce at√© esgotar todas as divis√µes poss√≠veis).\n",
    "\n",
    "- **Efeito pr√°tico:**  \n",
    "  - Valores baixos ‚Üí √°rvore mais rasa, com menos capacidade de ajuste.  \n",
    "  - Valores altos ‚Üí √°rvore mais profunda, com risco maior de overfitting.\n",
    "\n",
    "**üîπExemplo:**  \n",
    "Se `max_depth=5`, a √°rvore ter√°, no m√°ximo, 5 n√≠veis de profundidade.\n",
    "\n",
    "\n",
    "##### 2. `min_samples_split`\n",
    "\n",
    "- **Defini√ß√£o:**  \n",
    "N√∫mero m√≠nimo de amostras que um n√≥ deve conter para que ele possa ser dividido em dois novos n√≥s.\n",
    "\n",
    "- **Papel:**  \n",
    "Evita que a √°rvore se divida excessivamente, o que pode gerar overfitting.\n",
    "\n",
    "- **Valor padr√£o:** `2`\n",
    "\n",
    "- **Efeito pr√°tico:**  \n",
    "  - Valores maiores ‚Üí √°rvores menos complexas, com menos divis√µes.  \n",
    "  - Valores menores ‚Üí √°rvores mais profundas, com risco de overfitting.\n",
    "\n",
    "**üîπExemplo:**  \n",
    "Se `min_samples_split=10`, a √°rvore s√≥ dividir√° um n√≥ se ele contiver no m√≠nimo 10 amostras.\n",
    "\n",
    "\n",
    "##### 3. `min_samples_leaf`\n",
    "\n",
    "- **Defini√ß√£o:**  \n",
    "N√∫mero m√≠nimo de amostras que deve estar presente em cada **n√≥ folha** (ou terminal) da √°rvore.\n",
    "\n",
    "- **Papel:**  \n",
    "Evita que a √°rvore gere folhas com muito poucas amostras, tornando o modelo mais robusto.\n",
    "\n",
    "- **Valor padr√£o:** `1`\n",
    "\n",
    "- **Efeito pr√°tico:**  \n",
    "  - Valores maiores ‚Üí folhas mais \"densas\", com menos vari√¢ncia.  \n",
    "  - Valores menores ‚Üí folhas pequenas, com risco de overfitting.\n",
    "\n",
    "**üîπExemplo:**  \n",
    "Se `min_samples_leaf=5`, qualquer folha da √°rvore precisa conter, no m√≠nimo, 5 amostras.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. `min_weight_fraction_leaf`\n",
    "\n",
    "- **Defini√ß√£o:**  \n",
    "Fra√ß√£o m√≠nima do **peso total** (ou soma dos pesos) das amostras que um n√≥ folha deve representar.\n",
    "\n",
    "- **Papel:**  \n",
    "Garante que cada folha represente uma fra√ß√£o m√≠nima do conjunto ponderado, √∫til especialmente em datasets com amostras de pesos desbalanceados.\n",
    "\n",
    "- **Valor padr√£o:** `0.0`\n",
    "\n",
    "- **Efeito pr√°tico:**  \n",
    "  - Se for `0.0`, esse crit√©rio √© ignorado.  \n",
    "  - Valores maiores restringem a forma√ß√£o de folhas com peso muito pequeno.\n",
    "\n",
    "**üîπExemplo:**  \n",
    "Se `min_weight_fraction_leaf=0.1` e o peso total das amostras √© `1.0`, cada folha dever√° conter amostras cujo peso combinado seja, no m√≠nimo, `0.1`.\n",
    "\n",
    "---\n",
    "\n",
    "##### 5. `max_leaf_nodes`\n",
    "\n",
    "- **Defini√ß√£o:**  \n",
    "N√∫mero m√°ximo de **n√≥s folha** que a √°rvore pode ter.\n",
    "\n",
    "- **Papel:**  \n",
    "Restringe o crescimento da √°rvore, atuando como uma forma de **poda pr√©via**.\n",
    "\n",
    "- **Valor padr√£o:** `None` (sem limite)\n",
    "\n",
    "- **Efeito pr√°tico:**  \n",
    "  - Limitar o n√∫mero de folhas ‚Üí √°rvore mais simples, menos propensa a overfitting.  \n",
    "  - Sem limite ‚Üí √°rvore pode crescer at√© que outros crit√©rios de parada sejam atingidos.\n",
    "\n",
    "**üîπExemplo:**  \n",
    "Se `max_leaf_nodes=10`, a √°rvore ser√° constru√≠da de forma √≥tima, mas conter√° no m√°ximo 10 n√≥s folha.\n",
    "\n",
    "\n",
    "#### ‚úÖ **Resumo pr√°tico:**\n",
    "\n",
    "| Hiperpar√¢metro | Controle |\n",
    "|----------------|----------|\n",
    "| `max_depth` | Profundidade m√°xima da √°rvore |\n",
    "| `min_samples_split` | Evita divis√µes excessivas |\n",
    "| `min_samples_leaf` | Garante folhas com amostras m√≠nimas |\n",
    "| `min_weight_fraction_leaf` | Garante folhas com peso m√≠nimo |\n",
    "| `max_leaf_nodes` | Limita o n√∫mero de folhas |\n",
    "\n",
    "\n",
    ">#### üí° **Dica:**  \n",
    ">Ajustar esses hiperpar√¢metros √© fundamental para equilibrar **vi√©s** e **vari√¢ncia** na constru√ß√£o de modelos de √°rvores, prevenindo tanto **overfitting** quanto **underfitting**.\n",
    "\n",
    "> ‚ö†Ô∏è **Importante:**  \n",
    "> O CART √© um **algoritmo guloso** (*greedy*): ele busca avidamente a melhor divis√£o poss√≠vel no **n√≠vel atual**, e depois repete o processo nos n√≠veis subsequentes, sem considerar se essas escolhas levar√£o √† **melhor solu√ß√£o global** em n√≠veis mais profundos. Embora isso normalmente resulte em uma solu√ß√£o **razoavelmente boa**, ela n√£o √© garantidamente a **√≥tima**.\n",
    "\n",
    "Infelizmente, encontrar a **√°rvore √≥tima** √© um problema conhecido como **NP-Completo**, o que significa que a sua resolu√ß√£o requer um tempo exponencial em rela√ß√£o ao n√∫mero de inst√¢ncias, `O(exp(m))`, tornando-o **intrat√°vel** mesmo para conjuntos de treinamento de tamanho relativamente pequeno. Por essa raz√£o, aceitamos uma solu√ß√£o que seja **\"boa o suficiente\"** em vez de buscar a perfei√ß√£o absoluta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfdf05f",
   "metadata": {},
   "source": [
    "### Fun√ß√µes de Impureza: Gini, Entropia e SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502417a",
   "metadata": {},
   "source": [
    "As fun√ß√µes de impureza s√£o **m√©tricas** utilizadas por algoritmos de √°rvores de decis√£o para **avaliar a qualidade** de uma divis√£o (split). A ideia central √©: quanto mais ‚Äúpuro‚Äù for um subconjunto ‚Äî ou seja, quanto mais ele contiver apenas uma classe ‚Äî, melhor √© a divis√£o. Dentre as fun√ß√µes de impureza mais usadas destacam-se a **Impureza de Gini** e a **Entropia** (baseada na Teoria da Informa√ß√£o). Para tarefas de **regress√£o**, usa-se uma outra m√©trica: o **Soma do Quadrado dos Res√≠duos** (*Sum Squared Error*, SSE).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Impureza de Gini\n",
    "\n",
    "##### **1. Intui√ß√£o**\n",
    "\n",
    "A Impureza de Gini mede a **probabilidade** de que uma inst√¢ncia escolhida **aleatoriamente** do conjunto de dados seja **classificada incorretamente** se for rotulada aleatoriamente segundo a **distribui√ß√£o de classes** no conjunto.\n",
    "\n",
    "Ou seja, quanto mais **misturadas** estiverem as classes, maior ser√° a impureza. Se todas as inst√¢ncias pertencem a uma √∫nica classe, a impureza √© zero.\n",
    "\n",
    "---\n",
    "\n",
    "##### **2. Formula√ß√£o Matem√°tica**\n",
    "\n",
    "Dado um conjunto de dados com $K$ classes, a impureza de Gini √© definida como:\n",
    "\n",
    "$$\n",
    "G = 1 - \\sum_{k=1}^K p_k^2\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $p_k$ ‚Üí propor√ß√£o (probabilidade) das inst√¢ncias da classe $k$ no conjunto.\n",
    "\n",
    "---\n",
    "\n",
    "##### **3. Como se chega nessa f√≥rmula?**\n",
    "\n",
    "A ideia central do √≠ndice de Gini √© medir **o grau de impureza** de um n√≥, ou seja, **a probabilidade de erro** ao classificar aleatoriamente uma inst√¢ncia segundo a distribui√ß√£o das classes presentes.\n",
    "\n",
    "##### Passo a passo intuitivo:\n",
    "\n",
    "1. A chance de pegar uma inst√¢ncia da classe $k$ √©:  \n",
    "$$ p_k $$\n",
    "\n",
    "2. A chance de **n√£o** pegar uma inst√¢ncia da classe $k$ √©:  \n",
    "$$ 1 - p_k $$\n",
    "\n",
    "3. **O que significa a multiplica√ß√£o $p_k(1 - p_k)$?**  \n",
    "Ela representa a **probabilidade de cometer um erro** ao **classificar aleatoriamente** uma inst√¢ncia como sendo da classe $k$:  \n",
    "- $p_k$ ‚Üí probabilidade de encontrar a classe $k$ no conjunto.  \n",
    "- $(1 - p_k)$ ‚Üí probabilidade de n√£o ser da classe $k$ (ou seja, de ser de uma das outras classes).\n",
    "\n",
    "Ent√£o, se voc√™ escolhe aleatoriamente uma inst√¢ncia, existe uma chance $p_k$ dela ser da classe $k$, mas se voc√™ **chutar** que ela √© de outra classe, a chance de errar nesse chute, considerando a distribui√ß√£o, est√° relacionada a $(1 - p_k)$.  \n",
    "\n",
    "A soma de todas essas combina√ß√µes de **probabilidade de pertencer a uma classe** vezes a **probabilidade de n√£o pertencer √† mesma classe** nos d√° a **expectativa de erro** ao tentar classificar sem uma regra precisa:\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K p_k(1 - p_k)\n",
    "$$\n",
    "\n",
    "Esse somat√≥rio avalia a **probabilidade total de erro** ao classificar uma inst√¢ncia aleatoriamente conforme a distribui√ß√£o das classes no n√≥.\n",
    "\n",
    "##### Passo seguinte: expandindo a express√£o\n",
    "\n",
    "Aplicamos a distributiva:\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K (p_k - p_k^2) = \\sum_{k=1}^K p_k - \\sum_{k=1}^K p_k^2\n",
    "$$\n",
    "\n",
    "Sabemos que a soma de todas as probabilidades das classes √© sempre igual a 1:\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K p_k = 1\n",
    "$$\n",
    "\n",
    "Portanto, substituindo:\n",
    "\n",
    "$$\n",
    "1 - \\sum_{k=1}^K p_k^2\n",
    "$$\n",
    "\n",
    "##### Conclus√£o:\n",
    "\n",
    "Assim, chegamos √† **f√≥rmula cl√°ssica** do √≠ndice de Gini:\n",
    "\n",
    "$$\n",
    "G = 1 - \\sum_{k=1}^K p_k^2\n",
    "$$\n",
    "\n",
    "##### Interpreta√ß√£o final:\n",
    "\n",
    "- Quando a distribui√ß√£o √© **muito desigual** (uma classe domina), o Gini √© **baixo** ‚Üí **alta pureza**.  \n",
    "- Quando as classes s√£o **bem distribu√≠das**, o Gini √© **alto** ‚Üí **alta impureza**.\n",
    "\n",
    "##### **Resumo intuitivo:**\n",
    "\n",
    "**O produto $p_k(1 - p_k)$ representa a chance de erro ao tentar classificar uma inst√¢ncia da classe $k$ como sendo de outra classe.**  \n",
    "\n",
    "O somat√≥rio acumula essas chances de erro para **todas as classes**, nos dando um **indicador de impureza** do n√≥.\n",
    "\n",
    "---\n",
    "\n",
    "##### **4. Propriedades Importantes**\n",
    "\n",
    "- $G = 0$ ‚Üí Conjunto puro (todas as inst√¢ncias s√£o da mesma classe).\n",
    "- $G$ m√°ximo ‚Üí quando as classes est√£o igualmente distribu√≠das.\n",
    "\n",
    "Por exemplo, para duas classes com $p = 0.5$, temos:\n",
    "\n",
    "$$\n",
    "G = 1 - (0.5^2 + 0.5^2) = 0.5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Entropia (Impureza da Informa√ß√£o)\n",
    "\n",
    "##### **1. Intui√ß√£o**\n",
    "\n",
    "A **Entropia** mede o grau de **incerteza** ou **imprevisibilidade** associado √† distribui√ß√£o das classes. Inspirada na Teoria da Informa√ß√£o de Claude Shannon, ela quantifica a **quantidade m√©dia de informa√ß√£o** necess√°ria para identificar a classe de uma inst√¢ncia.\n",
    "\n",
    "Quanto maior a mistura de classes, maior a entropia.\n",
    "\n",
    "---\n",
    "\n",
    "##### **2. Formula√ß√£o Matem√°tica**\n",
    "\n",
    "Dado um conjunto com $K$ classes, a Entropia $H$ √© dada por:\n",
    "\n",
    "$$\n",
    "H = -\\sum_{k=1}^K p_k \\log_2(p_k)\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $p_k$ ‚Üí propor√ß√£o das inst√¢ncias da classe $k$.\n",
    "\n",
    "---\n",
    "\n",
    "##### **3. Como se chega nessa f√≥rmula?**\n",
    "\n",
    "O racioc√≠nio vem da **Teoria da Informa√ß√£o**:\n",
    "\n",
    "1. A **informa√ß√£o** associada ao evento da classe $k$ √©:\n",
    "\n",
    "$$\n",
    "I(p_k) = -\\log_2(p_k)\n",
    "$$\n",
    "\n",
    "Isso significa que quanto mais **improv√°vel** for o evento, maior √© a informa√ß√£o obtida ao observ√°-lo.\n",
    "\n",
    "2. O valor esperado da informa√ß√£o (ou seja, a m√©dia ponderada) √©:\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K p_k \\cdot I(p_k) = -\\sum_{k=1}^K p_k \\log_2(p_k)\n",
    "$$\n",
    "\n",
    "Portanto, a Entropia √© essa **m√©dia ponderada**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **4. Exemplifica√ß√£o**\n",
    "\n",
    "Para duas classes balanceadas: $p_1 = 0.5$ e $p_2 = 0.5$:\n",
    "\n",
    "$$\n",
    "H = - (0.5 \\log_2 0.5 + 0.5 \\log_2 0.5) = - (0.5(-1) + 0.5(-1)) = 1\n",
    "$$\n",
    "\n",
    "Ou seja, entropia m√°xima = $1$ bit.\n",
    "\n",
    "Se o conjunto for puro (ex.: $p_1 = 1$, $p_2 = 0$):\n",
    "\n",
    "$$\n",
    "H = - (1 \\cdot \\log_2 1 + 0 \\cdot \\log_2 0) = 0\n",
    "$$\n",
    "\n",
    "(Nota: $0 \\log 0 = 0$ por conven√ß√£o).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Compara√ß√£o entre Gini e Entropia\n",
    "\n",
    "| Crit√©rio          | Impureza de Gini                          | Entropia                                  |\n",
    "|-------------------|------------------------------------------|-------------------------------------------|\n",
    "| Interpreta√ß√£o     | Probabilidade de erro aleat√≥rio          | M√©dia da informa√ß√£o necess√°ria            |\n",
    "| C√°lculo           | $1 - \\sum p_k^2$                         | $-\\sum p_k \\log_2(p_k)$                   |\n",
    "| Complexidade      | Mais simples, computacionalmente leve    | Mais complexa, envolve logaritmos         |\n",
    "| Aplica√ß√£o         | Muito usada no CART                      | Usada em ID3, C4.5 e outros algoritmos    |\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Qual √© melhor?\n",
    "\n",
    "Ambas s√£o muito utilizadas e produzem resultados **similares** na pr√°tica. A escolha depende de:\n",
    "\n",
    "- **Efici√™ncia computacional** ‚Üí Gini √© mais r√°pida.\n",
    "- **Interpreta√ß√£o te√≥rica** ‚Üí Entropia tem uma base mais s√≥lida na Teoria da Informa√ß√£o.\n",
    "\n",
    "Em implementa√ß√µes como a do **Scikit-Learn**, o padr√£o √© usar a **Impureza de Gini**, mas a **Entropia** pode ser facilmente especificada.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Sum Squared Error (SSE)\n",
    "\n",
    "Para tarefas de **regress√£o** com √°rvores de decis√£o, como a **Decision Tree Regressor**, ao inv√©s de usar Gini ou Entropia, utilizamos o **Soma do Quadrado dos Res√≠duos (SSE)** como fun√ß√£o de custo.\n",
    "\n",
    "---\n",
    "\n",
    "##### **1. Intui√ß√£o**\n",
    "\n",
    "O SSE mede a **soma dos quadrados dos erros** entre os valores reais e os valores previstos. Quanto **menor** for o SSE, **melhor** a divis√£o, pois significa que os valores previstos est√£o mais pr√≥ximos dos reais.\n",
    "\n",
    "---\n",
    "\n",
    "##### **2. Formula√ß√£o Matem√°tica**\n",
    "\n",
    "Dado um conjunto $S$ com $n$ inst√¢ncias, a fun√ß√£o de custo √©:\n",
    "\n",
    "$$\n",
    "SSE = \\sum_{i=1}^n (y_i - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $y_i$ ‚Üí valor real da $i$-√©sima inst√¢ncia.\n",
    "- $\\hat{y}$ ‚Üí m√©dia dos valores no subconjunto $S$.\n",
    "\n",
    "---\n",
    "\n",
    "##### **3. Como se chega nessa f√≥rmula?**\n",
    "\n",
    "1. Para cada inst√¢ncia, calculamos o **erro**: $y_i - \\hat{y}$.\n",
    "2. Elevamos ao **quadrado** para penalizar erros maiores.\n",
    "\n",
    "Esse processo minimiza a vari√¢ncia dentro de cada subconjunto criado pela divis√£o.\n",
    "\n",
    "---\n",
    "\n",
    "##### **4. Propriedades Importantes**\n",
    "\n",
    "- SSE √© sempre **n√£o-negativo**.\n",
    "- O **menor valor poss√≠vel** do SSE √© **zero**, indicando previs√£o perfeita.\n",
    "- Muito **sens√≠vel a outliers**, pois penaliza fortemente erros grandes.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Uso em √Årvores de Regress√£o**\n",
    "\n",
    "Ao construir uma **√°rvore de regress√£o**, o algoritmo escolhe as divis√µes que **minimizam o SSE** nos subconjuntos resultantes.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Formula√ß√£o de G√©ron: Fun√ß√£o de Custo do CART para Regress√£o**\n",
    "\n",
    "O algoritmo CART busca dividir o conjunto de treinamento de modo a **minimizar** a seguinte fun√ß√£o de custo:\n",
    "\n",
    "$$\n",
    "J(k, t_k) = \\frac{m_{\\text{left}}}{m} SSE_{\\text{left}} + \\frac{m_{\\text{right}}}{m} SSE_{\\text{right}}\n",
    "$$\n",
    "\n",
    "onde:\n",
    "\n",
    "- $m$ ‚Üí n√∫mero total de inst√¢ncias no n√≥.\n",
    "- $m_{\\text{left}}$ ‚Üí n√∫mero de inst√¢ncias no subconjunto da esquerda.\n",
    "- $m_{\\text{right}}$ ‚Üí n√∫mero de inst√¢ncias no subconjunto da direita.\n",
    "- $SSE_{\\text{left}}$ ‚Üí SSE do subconjunto da esquerda.\n",
    "- $SSE_{\\text{right}}$ ‚Üí SSE do subconjunto da direita.\n",
    "\n",
    "---\n",
    "\n",
    "**E o SSE de cada n√≥ √© dado por:**\n",
    "\n",
    "$$\n",
    "SSE_{\\text{node}} = \\sum_{i \\in \\text{node}} \\left( \\hat{y}_{\\text{node}} - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "sendo que:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{node}} = \\dfrac{\\sum\\limits_{i\\ \\in\\ \\text{node}} y^{(i)}}{m_{\\text{node}}}\n",
    "$$\n",
    "\n",
    "Ou seja, a divis√£o √≥tima √© aquela que **minimiza a soma ponderada dos SSEs** dos dois subconjuntos resultantes.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Resumo\n",
    "\n",
    "| Tipo de Problema | Fun√ß√£o de Impureza/Custo                   |\n",
    "|------------------|-------------------------------------------|\n",
    "| Classifica√ß√£o    | Impureza de Gini ou Entropia              |\n",
    "| Regress√£o        | Sum Squared Error (SSE)                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1f047",
   "metadata": {},
   "source": [
    "### Classifica√ß√£o de √Årvore de Decis√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fdbf76",
   "metadata": {},
   "source": [
    "Para entender as √Årvore de Decis√£o, vamos criar uma e dar uma espiada como ela faz as predi√ß√µes. O c√≥digo a seguir treina um ``DecisionTreeClassifier`` no conjunto de dados da √≠ris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a base de dados Iris como um DataFrame do pandas\n",
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "# Seleciona duas caracter√≠sticas (features) espec√≠ficas: comprimento e largura da p√©tala\n",
    "# Converte para um array numpy com .values para uso no modelo\n",
    "X_iris = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "\n",
    "# Obt√©m os r√≥tulos/classes das amostras (0, 1 ou 2) para as tr√™s esp√©cies de Iris\n",
    "y_iris = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e622828",
   "metadata": {},
   "source": [
    "#### Crit√©rio **GINI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63566e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um classificador de √°rvore de decis√£o com profundidade m√°xima 2 para evitar overfitting\n",
    "# Define random_state para garantir que a divis√£o e resultados sejam reprodut√≠veis\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "# Treina o classificador com as caracter√≠sticas X_iris e as classes y_iris\n",
    "tree_clf.fit(X_iris, y_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32c9bd",
   "metadata": {},
   "source": [
    "O ``plot_tree`` √© uma fun√ß√£o do ``sklearn.tree`` que permite visualizar diretamente uma √°rvore de decis√£o, sem necessidade de ferramentas externas como **Graphviz**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c915c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a nova pasta, se n√£o existir\n",
    "output_dir = \"figuras\"  # nome da pasta\n",
    "os.makedirs(output_dir, exist_ok=True)  # cria a pasta; n√£o d√° erro se j√° existir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f391a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova figura com tamanho personalizado: largura = 12 polegadas, altura = 8 polegadas\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plota a √°rvore de decis√£o treinada (tree_clf)\n",
    "plot_tree(\n",
    "    tree_clf,  # modelo de √°rvore de decis√£o treinado\n",
    "    feature_names=[\"petal length (cm)\", \"petal width (cm)\"],  # nomes das features para exibir nos n√≥s\n",
    "    class_names=iris.target_names,  # nomes das classes para mostrar nas folhas\n",
    "    filled=True,  # preenche os n√≥s com cores conforme a classe majorit√°ria\n",
    "    rounded=True  # bordas arredondadas para melhor est√©tica\n",
    ")\n",
    "\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"decision_tree_plot_1.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Exibe a figura gerada\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f00c79",
   "metadata": {},
   "source": [
    "#### Crit√©rio **ENTROPY (ID3):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um classificador de √°rvore de decis√£o com profundidade m√°xima 2 para evitar overfitting\n",
    "# Define random_state para garantir que a divis√£o e resultados sejam reprodut√≠veis\n",
    "tree_clf_Ent = DecisionTreeClassifier(max_depth=2, random_state=42, criterion='entropy')\n",
    "\n",
    "# Treina o classificador com as caracter√≠sticas X_iris e as classes y_iris\n",
    "tree_clf_Ent.fit(X_iris, y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma nova figura com tamanho personalizado: largura = 12 polegadas, altura = 8 polegadas\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plota a √°rvore de decis√£o treinada (tree_clf)\n",
    "plot_tree(\n",
    "    tree_clf_Ent,  # modelo de √°rvore de decis√£o treinado\n",
    "    feature_names=[\"petal length (cm)\", \"petal width (cm)\"],  # nomes das features para exibir nos n√≥s\n",
    "    class_names=iris.target_names,  # nomes das classes para mostrar nas folhas\n",
    "    filled=True,  # preenche os n√≥s com cores conforme a classe majorit√°ria\n",
    "    rounded=True  # bordas arredondadas para melhor est√©tica\n",
    ")\n",
    "\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"decision_tree_plot_2.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Exibe a figura gerada\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f312e7",
   "metadata": {},
   "source": [
    "#### **Gr√°fico de fronteiras de decis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ac058",
   "metadata": {},
   "source": [
    "Em classifica√ß√£o supervisionada, o modelo aprende a separar classes com base em caracter√≠sticas (features). A fronteira de decis√£o √© a linha ou superf√≠cie que divide o espa√ßo de atributos em regi√µes, onde cada regi√£o corresponde a uma previs√£o de classe distinta.\n",
    "\n",
    "No caso das √Årvores de Decis√£o, a fronteira √© formada por divis√µes retangulares e ortogonais (linhas horizontais ou verticais), resultantes das compara√ß√µes do tipo:\n",
    "\n",
    ">Se ``feature ‚â§ threshold`` vai para um lado; sen√£o, vai para outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7557b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.meshgrid cria duas matrizes bidimensionais a partir de dois vetores unidimensionais.\n",
    "# Essas matrizes representam uma grade de coordenadas de comprimento e largura das p√©talas.\n",
    "lengths, widths = np.meshgrid(\n",
    "    np.linspace(0, 7.2, 100),  # np.linspace gera 100 pontos igualmente espa√ßados entre 0 e 7.2 cm para o comprimento da p√©tala (eixo x).\n",
    "    np.linspace(0, 3, 100)     # np.linspace gera 100 pontos igualmente espa√ßados entre 0 e 3 cm para a largura da p√©tala (eixo y).\n",
    ")\n",
    "\n",
    "# A fun√ß√£o ravel \"achata\" (flatten) os arrays lengths e widths em vetores unidimensionais.\n",
    "# np.c_ concatena esses dois vetores coluna a coluna, formando um array de shape (10000, 2),\n",
    "# onde cada linha √© uma combina√ß√£o √∫nica de comprimento e largura das p√©talas.\n",
    "X_iris_all = np.c_[lengths.ravel(), widths.ravel()]\n",
    "\n",
    "# A √°rvore de decis√£o j√° treinada (tree_clf) faz a predi√ß√£o de classe para cada uma das 10.000 combina√ß√µes\n",
    "# de comprimento e largura da p√©tala contidas em X_iris_all.\n",
    "# Isso gera um array de 10.000 elementos, cada um com a classe prevista.\n",
    "\n",
    "# Como queremos visualizar os resultados na forma de uma malha (grade) 2D, igual ao formato original,\n",
    "# usamos reshape para transformar o array de predi√ß√µes para o mesmo shape das matrizes lengths e widths: (100, 100).\n",
    "y_pred = tree_clf.predict(X_iris_all).reshape(lengths.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria√ß√£o de colormap personalizado para diferenciar as 3 classes\n",
    "custom_cmap = ListedColormap(['#fafab0', '#9898ff', '#a0faa0'])\n",
    "# Utiliza cores espec√≠ficas para representar visualmente cada classe.\n",
    "# '#fafab0': amarelo claro, '#9898ff': azul claro, '#a0faa0': verde claro.\n",
    "\n",
    "# Define o tamanho da figura: 8 polegadas de largura, 4 de altura\n",
    "plt.figure(figsize=(8, 4))\n",
    "# Cria uma nova figura com dimens√£o espec√≠fica para melhor visualiza√ß√£o.\n",
    "\n",
    "# Cria um gr√°fico de contorno preenchido (contourf) para visualizar as regi√µes de decis√£o da √°rvore.\n",
    "# Cada regi√£o ser√° preenchida com uma cor que representa a classe prevista para os pontos naquela √°rea.\n",
    "# 'lengths' e 'widths' s√£o as coordenadas da grade (malha) de poss√≠veis combina√ß√µes de comprimento e largura da p√©tala.\n",
    "# 'y_pred' cont√©m a classe prevista para cada ponto dessa grade pela √°rvore de decis√£o.\n",
    "# O par√¢metro 'alpha=0.3' define a transpar√™ncia das cores:\n",
    "#    - Transpar√™ncia parcial (30%) permite que os pontos reais do conjunto de dados sejam visualizados sobre as regi√µes coloridas.\n",
    "# 'cmap=custom_cmap' aplica um colormap personalizado para distinguir visualmente as classes.\n",
    "plt.contourf(lengths, widths, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "\n",
    "\n",
    "# Itera sobre as tr√™s classes de flores Iris: setosa, versicolor e virginica.\n",
    "# 'enumerate' fornece o √≠ndice da classe (idx) e seu respectivo nome (name).\n",
    "# 'zip' associa cada nome de classe com um estilo de marcador espec√≠fico:\n",
    "#    - \"yo\" ‚Üí amarelo com marcador circular (setosa).\n",
    "#    - \"bs\" ‚Üí azul com marcador quadrado (versicolor).\n",
    "#    - \"g^\" ‚Üí verde com marcador triangular (virginica).\n",
    "for idx, (name, style) in enumerate(zip(iris.target_names, (\"yo\", \"bs\", \"g^\"))):\n",
    "    \n",
    "    # Seleciona os pontos do conjunto de dados que pertencem √† classe atual.\n",
    "    # X_iris[:, 0] ‚Üí comprimento da p√©tala.\n",
    "    # X_iris[:, 1] ‚Üí largura da p√©tala.\n",
    "    # y_iris == idx ‚Üí filtro booleano para pegar apenas as inst√¢ncias da classe 'idx'.\n",
    "    plt.plot(\n",
    "        X_iris[:, 0][y_iris == idx],  # Eixo x: comprimento das p√©talas da classe atual.\n",
    "        X_iris[:, 1][y_iris == idx],  # Eixo y: largura das p√©talas da classe atual.\n",
    "        style,  # Estilo visual: define a cor e o formato do marcador para a classe.\n",
    "        label=f\"Iris {name}\"  # Define o r√≥tulo da legenda com o nome da classe.\n",
    "    )\n",
    "\n",
    "# Resultado: para cada uma das 3 classes, plota os pontos reais do dataset \n",
    "# sobre o gr√°fico, com diferentes cores e formatos para facilitar a identifica√ß√£o visual.\n",
    "\n",
    "\n",
    "# Cria uma √°rvore com profundidade m√°xima de 3, para melhor visualiza√ß√£o das divis√µes\n",
    "tree_clf_deeper = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "# Cria uma nova √°rvore de decis√£o com profundidade controlada para evitar sobreajuste\n",
    "# e para que o gr√°fico de divis√µes seja mais interpret√°vel.\n",
    "\n",
    "# Treina a nova √°rvore no conjunto de dados Iris\n",
    "tree_clf_deeper.fit(X_iris, y_iris)\n",
    "# Ajusta a √°rvore de decis√£o aos dados reais (treinamento).\n",
    "\n",
    "# Extrai os thresholds das divis√µes: √≠ndices espec√≠ficos dos n√≥s da √°rvore\n",
    "# Cada threshold corresponde a uma divis√£o no espa√ßo das features\n",
    "th0, th1, th2a, th2b = tree_clf_deeper.tree_.threshold[[0, 2, 3, 6]]\n",
    "# Acessa diretamente os thresholds (limiares) de decis√£o que a √°rvore aprendeu.\n",
    "# Estes thresholds definem as \"fronteiras\" no gr√°fico.\n",
    "\n",
    "# Define os r√≥tulos dos eixos\n",
    "plt.xlabel(\"Petal length (cm)\")\n",
    "plt.ylabel(\"Petal width (cm)\")\n",
    "# D√° nome aos eixos x e y para facilitar a leitura do gr√°fico.\n",
    "\n",
    "# Primeira divis√£o da √°rvore de decis√£o: uma linha vertical no limiar th0.\n",
    "# Representa a primeira decis√£o da √°rvore (n√≠vel de profundidade 0).\n",
    "# plt.plot desenha uma linha preta cont√≠nua (\"k-\") com largura de 2.\n",
    "# A linha vai de (th0, 0) at√© (th0, 3) ‚Äî atravessa todo o espa√ßo no eixo y.\n",
    "plt.plot([th0, th0], [0, 3], \"k-\", linewidth=2)\n",
    "\n",
    "# Segunda divis√£o da √°rvore: uma linha horizontal no limiar th1.\n",
    "# Representa a decis√£o de profundidade 1.\n",
    "# A linha come√ßa em th0 (ponto da primeira divis√£o) e vai at√© 7.2 no eixo x.\n",
    "# \"k--\" ‚Üí linha preta tracejada; linewidth=2 ‚Üí espessura da linha.\n",
    "plt.plot([th0, 7.2], [th1, th1], \"k--\", linewidth=2)\n",
    "\n",
    "# Terceira divis√£o: uma linha vertical no limiar th2a.\n",
    "# Refina a divis√£o da regi√£o inferior do espa√ßo (abaixo de th1).\n",
    "# \"k:\" ‚Üí linha preta pontilhada.\n",
    "plt.plot([th2a, th2a], [0, th1], \"k:\", linewidth=2)\n",
    "\n",
    "# Quarta divis√£o: uma linha vertical no limiar th2b.\n",
    "# Refina a divis√£o da regi√£o superior do espa√ßo (acima de th1).\n",
    "# Tamb√©m desenhada como linha preta pontilhada.\n",
    "plt.plot([th2b, th2b], [th1, 3], \"k:\", linewidth=2)\n",
    "\n",
    "# Essas quatro linhas visuais mostram como a √°rvore de decis√£o segmenta o espa√ßo de atributos\n",
    "# (comprimento e largura da p√©tala) em regi√µes, cada uma associada a uma classe.\n",
    "\n",
    "\n",
    "# Adiciona textos indicando a profundidade de cada divis√£o\n",
    "plt.text(th0 - 0.05, 1.0, \"Depth=0\", horizontalalignment=\"right\", fontsize=15)\n",
    "plt.text(3.2, th1 + 0.02, \"Depth=1\", verticalalignment=\"bottom\", fontsize=13)\n",
    "plt.text(th2a + 0.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
    "# Insere r√≥tulos no gr√°fico para indicar claramente o n√≠vel de profundidade\n",
    "# de cada divis√£o da √°rvore.\n",
    "\n",
    "# Define os limites dos eixos\n",
    "plt.axis([0, 7.2, 0, 3])\n",
    "# Ajusta os limites do gr√°fico conforme o range dos dados de comprimento e largura das p√©talas.\n",
    "\n",
    "# Adiciona a legenda com os nomes das classes\n",
    "plt.legend()\n",
    "# Insere a legenda no gr√°fico para identificar as classes com base nos marcadores e cores.\n",
    "\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"Fronteira_de_Decisao.png\")\n",
    "# Monta o caminho completo onde a imagem gerada ser√° salva.\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "# Salva o gr√°fico com alta resolu√ß√£o (300 dpi) e com limites ajustados para evitar cortes.\n",
    "\n",
    "# Exibe o gr√°fico\n",
    "plt.show()\n",
    "# Exibe o gr√°fico na tela, √∫til em notebooks e scripts interativos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a3596",
   "metadata": {},
   "source": [
    "O gr√°fico gerado representa as fronteiras de decis√£o de uma √Årvore de Decis√£o treinada para classificar amostras de flores Iris com base em duas caracter√≠sticas:\n",
    "\n",
    "- Comprimento da p√©tala (``petal length``)\n",
    "\n",
    "- Largura da p√©tala (``petal width``)\n",
    "\n",
    "**‚úÖ Como funciona a fronteira de decis√£o:**\n",
    "\n",
    "- O espa√ßo de atributos (comprimento √ó largura) √© **dividido em regi√µes** onde cada regi√£o corresponde a uma **classe predita** pela √°rvore.\n",
    "\n",
    "- As **linhas verticais ou horizontais** representam **limiares (thresholds)** onde a √°rvore faz uma **divis√£o (split)**.\n",
    "\n",
    "- A **primeira divis√£o** (linha mais grossa) ocorre no n√≥ raiz (profundidade 0), separando os dados com base no **comprimento da p√©tala = 2.45 cm**:\n",
    "\n",
    "    - A √°rea √† esquerda √© pura (apenas Iris-setosa), ent√£o n√£o precisa de mais divis√µes.\n",
    "\n",
    "    - A √°rea √† direita √© impura (mistura de Iris-versicolor e Iris-virginica), ent√£o ocorre uma nova divis√£o.\n",
    "\n",
    "- O segundo split ocorre em **largura da p√©tala = 1.75 cm** (linha tracejada), que separa ainda mais os dados.\n",
    "\n",
    "- Como o ``max_depth`` foi configurado para 2, a √°rvore para nesse ponto.\n",
    "Se configur√°ssemos ``max_depth=3``, mais duas subdivis√µes ocorreriam, adicionando novas linhas pontilhadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d958e",
   "metadata": {},
   "source": [
    "#### Estimando Classe de Probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730c04f",
   "metadata": {},
   "source": [
    "Uma √Årvore de Decis√£o tamb√©m pode estimar a probabilidade de uma inst√¢ncia pertencer a uma determinada classe $ k $. Para isso, a √°rvore percorre seus n√≥s at√© encontrar a folha correspondente √†quela inst√¢ncia. Em seguida, ela retorna a propor√ß√£o de inst√¢ncias de treinamento daquela classe $ k $ presentes nessa folha. Por exemplo, suponha que voc√™ tenha uma flor cujas p√©talas medem 5 cm de comprimento e 1,5 cm de largura. A folha encontrada ao percorrer a √°rvore √© a folha √† esquerda no n√≠vel de profundidade 2. Nesse caso, a √°rvore de decis√£o deve fornecer as seguintes probabilidades: 0% para Iris setosa (0 de 54 inst√¢ncias nessa folha), 90,7% para Iris versicolor (49 de 54 inst√¢ncias) e 9,3% para Iris virginica (5 de 54 inst√¢ncias). Ao pedir uma predi√ß√£o de classe, o modelo deve retornar Iris versicolor (classe 1), pois √© a classe com maior probabilidade. Vamos verificar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos o m√©todo predict_proba para obter as probabilidades previstas pelo classificador\n",
    "# para a inst√¢ncia com caracter√≠sticas [5, 1.5] (p√©talas de 5 cm e 1,5 cm de largura).\n",
    "# O m√©todo retorna um array com as probabilidades de cada classe para essa inst√¢ncia.\n",
    "# Usamos .round(3) para arredondar as probabilidades para 3 casas decimais, facilitando a visualiza√ß√£o.\n",
    "tree_clf.predict_proba([[5, 1.5]]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos o m√©todo predict para prever a classe da inst√¢ncia com caracter√≠sticas [5, 1.5].\n",
    "# O m√©todo retorna a classe com a maior probabilidade, ou seja, a previs√£o final do modelo.\n",
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ddaf9",
   "metadata": {},
   "source": [
    ">VAMOS FAZER MANUALMENTE UMA √ÅRVORE DE DECIS√ÇO DE CLASSIFICA√á√ÇO\n",
    "\n",
    "| ID | F1 | F2 | F3 | Classe |\n",
    "| -- | -- | -- | -- | ------ |\n",
    "| 1  | 2  | 7  | 5  | A      |\n",
    "| 2  | 3  | 6  | 5  | A      |\n",
    "| 3  | 4  | 8  | 7  | B      |\n",
    "| 4  | 5  | 7  | 8  | B      |\n",
    "| 5  | 6  | 9  | 9  | B      |\n",
    "| 6  | 7  | 6  | 8  | C      |\n",
    "| 7  | 8  | 5  | 7  | C      |\n",
    "| 8  | 9  | 4  | 6  | C      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e08e9",
   "metadata": {},
   "source": [
    "### Regress√£o de √Årvore de Decis√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e4cc0",
   "metadata": {},
   "source": [
    "As **√Årvores de Decis√£o** tamb√©m s√£o capazes de realizar **tarefas de regress√£o**. Diferente das √°rvores de classifica√ß√£o, que predizem r√≥tulos discretos, as √°rvores de regress√£o predizem **valores num√©ricos** minimizando uma fun√ß√£o de custo como o **Soma do Quadrado dos Res√≠duos (SSE - Sum Squared Error)**.\n",
    "\n",
    "Vamos construir uma **√°rvore de regress√£o** usando a classe `DecisionTreeRegressor` do **Scikit-Learn**. Iremos trein√°-la em um **conjunto de dados quadr√°tico com ru√≠do** e limitar a profundidade da √°rvore a **2**, para facilitar a visualiza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos uma semente aleat√≥ria para garantir a reprodutibilidade dos resultados.\n",
    "# Isso significa que, sempre que rodarmos o c√≥digo, obteremos os mesmos n√∫meros aleat√≥rios.\n",
    "np.random.seed(42)\n",
    "\n",
    "# Criamos a vari√°vel X_quad com 200 observa√ß√µes aleat√≥rias.\n",
    "# np.random.rand(200, 1) ‚Üí gera 200 valores entre 0 e 1.\n",
    "# Subtra√≠mos 0.5 para centralizar os dados entre -0.5 e +0.5.\n",
    "X_quad = np.random.rand(200, 1) - 0.5  \n",
    "\n",
    "# Agora criamos a vari√°vel dependente y_quad.\n",
    "# A rela√ß√£o entre X e y ser√° quadr√°tica: X_quad ** 2 ‚Üí eleva cada valor ao quadrado.\n",
    "# Adicionamos tamb√©m um ru√≠do aleat√≥rio com distribui√ß√£o normal (Gaussiana).\n",
    "# np.random.randn(200, 1) ‚Üí gera 200 valores de ru√≠do padr√£o com m√©dia 0 e vari√¢ncia 1.\n",
    "# Multiplicamos o ru√≠do por 0.025 para que ele seja pequeno, simulando incerteza ou varia√ß√£o nos dados.\n",
    "y_quad = X_quad ** 2 + 0.025 * np.random.randn(200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a971264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos o modelo de √Årvore de Decis√£o para Regress√£o.\n",
    "# A classe DecisionTreeRegressor √© usada para prever vari√°veis cont√≠nuas (regress√£o), ao contr√°rio da DecisionTreeClassifier, usada para classifica√ß√£o.\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(\n",
    "    max_depth=2,       # Par√¢metro que limita a profundidade m√°xima da √°rvore.\n",
    "                      # Neste caso, a √°rvore ter√° no m√°ximo dois n√≠veis de splits.\n",
    "                      # Isso evita o overfitting e garante uma estrutura mais simples e interpret√°vel.\n",
    "\n",
    "    random_state=42   # Define uma semente para garantir que a constru√ß√£o da √°rvore seja reprodut√≠vel.\n",
    "                      # Como existem empates ou aleatoriedade na escolha dos splits, isso garante sempre o mesmo resultado.\n",
    ")\n",
    "\n",
    "# Agora ajustamos o modelo aos dados.\n",
    "# O m√©todo fit realiza o treinamento: a √°rvore encontra os melhores pontos de divis√£o (splits) \n",
    "# nos dados, de forma a minimizar o soma do quadrado dos res√≠duos (SSE) em cada divis√£o.\n",
    "\n",
    "tree_reg.fit(X_quad, y_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma figura com tamanho maior para que a √°rvore fique leg√≠vel.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Usamos a fun√ß√£o plot_tree para desenhar a √°rvore de decis√£o treinada.\n",
    "plot_tree(\n",
    "    tree_reg,            # O modelo de √°rvore de decis√£o j√° treinado.\n",
    "    feature_names=[\"x1\"],# O nome da vari√°vel de entrada, que ser√° exibido nos n√≥s da √°rvore.\n",
    "    rounded=True,        # Deixa os cantos das caixas arredondados para uma visualiza√ß√£o mais est√©tica.\n",
    "    filled=True,         # Preenche os n√≥s com cores representando a escala dos valores previstos.\n",
    "    impurity=True,       # Mostra a impureza (SSE) de cada n√≥.\n",
    "    precision=3          # Define a quantidade de casas decimais exibidas nos valores.\n",
    ")\n",
    "\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"decision_tree_plot_3.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Exibimos o gr√°fico na tela.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b5990",
   "metadata": {},
   "source": [
    "Esta √°rvore de regress√£o √© muito semelhante √† √°rvore de classifica√ß√£o que vimos anteriormente, mas h√° uma diferen√ßa essencial: em vez de prever uma classe em cada n√≥, ela prev√™ um valor num√©rico. Por exemplo, suponha que desejamos fazer uma previs√£o para uma nova inst√¢ncia com `x = 0.6`. O processo de predi√ß√£o ocorre percorrendo a √°rvore a partir do n√≥ raiz, seguindo os ramos conforme as condi√ß√µes estabelecidas (como `x <= valor` ou `x > valor`), at√© alcan√ßar um n√≥ folha. Quando isso acontece, a √°rvore retorna um valor num√©rico ‚Äî no exemplo citado, esse valor seria `0.154`.\n",
    "\n",
    "Esse valor representa a m√©dia dos valores alvo (`y`) das 110 inst√¢ncias de treinamento que tamb√©m seguiram esse mesmo caminho na √°rvore e chegaram a essa folha. Al√©m disso, essa previs√£o est√° associada a uma soma do quadrado dos res√≠duos (SSE) de `0.002`, o que significa que, para essas 110 amostras, a soma dos quadrados das diferen√ßas entre os valores reais e o valor previsto √© relativamente baixa, indicando uma boa qualidade de ajuste naquele subconjunto de dados.\n",
    "\n",
    "Em resumo, a √°rvore de regress√£o funciona agrupando os dados em subconjuntos que sejam internamente homog√™neos em rela√ß√£o ao valor da vari√°vel dependente, e para cada grupo, faz a previs√£o utilizando a m√©dia das respostas observadas. A profundidade da √°rvore controla o n√≠vel de detalhe dessas divis√µes: √°rvores mais profundas criam grupos mais espec√≠ficos, podendo melhorar a precis√£o, mas tamb√©m aumentando o risco de *overfitting*, ou seja, de ajustar-se demais aos dados de treinamento e perder capacidade de generaliza√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77989b90",
   "metadata": {},
   "source": [
    "#### Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae0014",
   "metadata": {},
   "source": [
    "Primeiramente, criamos um novo modelo de √Årvore de Decis√£o para Regress√£o (`DecisionTreeRegressor`) com `max_depth=3`. Isso significa que a √°rvore poder√° ter at√© tr√™s n√≠veis de divis√£o, o que potencialmente permite capturar padr√µes mais complexos nos dados. A defini√ß√£o do `random_state=42` garante a reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30910c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um novo modelo de √Årvore de Decis√£o para Regress√£o.\n",
    "# Aqui definimos a profundidade m√°xima da √°rvore como 3.\n",
    "# Isso significa que ela pode realizar at√© 3 divis√µes (ou n√≠veis) para ajustar melhor o modelo aos dados.\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de69e3",
   "metadata": {},
   "source": [
    "Em seguida, treinamos esse modelo com os mesmos dados quadr√°ticos utilizados anteriormente (``X_quad`` e ``y_quad``). O m√©todo ``fit()`` √© respons√°vel por ajustar o modelo aos dados, ou seja, construir a estrutura da √°rvore de decis√£o baseada nesses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca6769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamos o modelo utilizando os mesmos dados quadr√°ticos gerados anteriormente.\n",
    "# O modelo aprende a partir desses dados e constr√≥i a √°rvore com base neles.\n",
    "tree_reg2.fit(X_quad, y_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7eba4",
   "metadata": {},
   "source": [
    "Ap√≥s o treinamento, podemos inspecionar a estrutura interna da √°rvore acessando o atributo ``tree_``. Mais especificamente, o atributo ``threshold`` armazena os valores de divis√£o que foram aprendidos em cada n√≥ interno da √°rvore. Esses limiares determinam como o espa√ßo de entrada foi particionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessamos os limiares (thresholds) dos n√≥s internos da √°rvore original (tree_reg).\n",
    "# O atributo 'tree_' cont√©m a estrutura interna da √°rvore ap√≥s o treinamento,\n",
    "# e 'threshold' mostra os valores das condi√ß√µes de divis√£o em cada n√≥.\n",
    "tree_reg.tree_.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185d879",
   "metadata": {},
   "source": [
    "Tamb√©m podemos verificar os limiares para a nova √°rvore treinada com profundidade 3, usando o mesmo atributo. Comparar os ``thresholds`` de √°rvores com diferentes profundidades √© uma maneira interessante de entender como a complexidade do modelo afeta suas divis√µes e sua capacidade de ajustar-se aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazemos o mesmo para a segunda √°rvore (tree_reg2), que possui uma profundidade maior.\n",
    "# Ao comparar os thresholds das duas √°rvores, podemos perceber como o aumento da profundidade\n",
    "# permite que o modelo fa√ßa divis√µes mais refinadas no espa√ßo de atributos.\n",
    "tree_reg2.tree_.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016e85",
   "metadata": {},
   "source": [
    "Este modelo tem suas previs√µes representadas √† esquerda na figura abaixo. Se voc√™ definir `max_depth=3`, obter√° as previs√µes representadas √† direita. Observe como o valor previsto para cada regi√£o √© sempre a m√©dia dos valores alvo (target) das inst√¢ncias daquela regi√£o. O algoritmo divide cada regi√£o de forma a fazer com que a maioria das inst√¢ncias de treinamento fiquem o mais pr√≥ximo poss√≠vel do valor previsto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca1527",
   "metadata": {},
   "source": [
    "#### Gr√°fico de Regress√£o de √Årvore de Decis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8256c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para plotar as previs√µes de um modelo de regress√£o baseado em √°rvore de decis√£o,\n",
    "# dentro de um intervalo de valores predefinido.\n",
    "def plot_regression_predictions(tree_reg, X, y, axes=[-0.5, 0.5, -0.05, 0.25]):\n",
    "    # Cria um array de 500 pontos uniformemente espa√ßados entre os valores axes[0] e axes[1].\n",
    "    # Esses pontos servem para gerar uma linha de previs√£o suave e cont√≠nua.\n",
    "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)  \n",
    "    # reshape(-1, 1) transforma o array 1D de shape (500,) ‚Äî vetor linha ‚Äî em um array 2D de shape (500, 1) ‚Äî matriz coluna.\n",
    "    # O par√¢metro -1 faz o NumPy calcular automaticamente o n√∫mero de linhas (500 neste caso).\n",
    "    # Esse formato (matriz coluna) √© exigido por muitos modelos do scikit-learn, que esperam uma matriz de amostras (linhas) por caracter√≠sticas (colunas).\n",
    "    \n",
    "    # Usa o modelo de √°rvore de decis√£o (tree_reg) previamente treinado para prever os valores de sa√≠da (y) \n",
    "    # correspondentes a cada um dos pontos x1.\n",
    "    y_pred = tree_reg.predict(x1)\n",
    "    \n",
    "    # Define os limites dos eixos do gr√°fico: [x_min, x_max, y_min, y_max], conforme passado por par√¢metro.\n",
    "    plt.axis(axes)\n",
    "    \n",
    "    # Rotula o eixo x com a nota√ß√£o LaTeX \"$x_1$\", indicando a vari√°vel independente.\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    \n",
    "    # Plota os pontos de dados reais utilizados no treinamento: X no eixo x e y no eixo y.\n",
    "    # \"b.\" significa cor azul (\"b\") e marcador de ponto (\".\").\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    \n",
    "    # Plota as previs√µes do modelo: pontos de x1 no eixo x e y_pred no eixo y.\n",
    "    # Estilo \"r.-\" significa linha cont√≠nua (\"-\"), de cor vermelha (\"r\") e com marcadores de ponto (\".\").\n",
    "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")  \n",
    "    # label √© o nome que aparecer√° na legenda, usando nota√ß√£o LaTeX para indicar y chap√©u (previs√£o).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e078652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma figura contendo duas subplots (gr√°ficos), organizados lado a lado (ncols=2),\n",
    "# com um tamanho de 10 por 4 polegadas.\n",
    "# sharey=True significa que ambos os gr√°ficos compartilham o mesmo eixo y.\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# Seleciona o primeiro eixo (gr√°fico da esquerda) para que os comandos de plotagem subsequentes\n",
    "# sejam aplicados a ele.\n",
    "plt.sca(axes[0])\n",
    "\n",
    "# Plota as previs√µes do modelo de √°rvore de decis√£o (tree_reg), treinado com profundidade m√°xima de 2,\n",
    "# junto com os dados reais, no primeiro gr√°fico.\n",
    "plot_regression_predictions(tree_reg, X_quad, y_quad)\n",
    "\n",
    "# Extrai os valores de threshold (limiares) que a √°rvore utilizou para realizar as divis√µes de decis√£o\n",
    "# nos n√≥s de profundidade 0 (raiz) e profundidade 1.\n",
    "# O atributo 'tree_' representa a estrutura interna da √°rvore, e 'threshold' armazena os valores de corte.\n",
    "# Aqui pegamos os thresholds dos n√≥s com √≠ndices 0 (raiz), 1 e 4.\n",
    "th0, th1a, th1b = tree_reg.tree_.threshold[[0, 1, 4]]\n",
    "\n",
    "# Para cada limiar obtido, plota uma linha vertical no gr√°fico para visualizar onde a √°rvore fez a divis√£o:\n",
    "# - 'k-' significa linha preta (\"k\" de \"black\"), estilo s√≥lido.\n",
    "# - 'k--' significa linha preta com estilo tracejado.\n",
    "for split, style in ((th0, \"k-\"), (th1a, \"k--\"), (th1b, \"k--\")):\n",
    "    # Cada linha √© desenhada de (split, y_min) at√© (split, y_max).\n",
    "    plt.plot([split, split], [-0.05, 0.25], style, linewidth=2)\n",
    "\n",
    "# Insere textos explicativos no gr√°fico, pr√≥ximos aos limiares.\n",
    "# Indica a profundidade da divis√£o da √°rvore.\n",
    "plt.text(th0, 0.16, \"Depth=0\", fontsize=15)  # Texto para a raiz (profundidade 0)\n",
    "plt.text(th1a + 0.01, -0.01, \"Depth=1\", horizontalalignment=\"center\", fontsize=13)  # Ajuste horizontal para clareza.\n",
    "plt.text(th1b + 0.01, -0.01, \"Depth=1\", fontsize=13)\n",
    "\n",
    "# Configura o r√≥tulo do eixo y com nota√ß√£o LaTeX, mantendo a rota√ß√£o vertical padr√£o desativada (rotation=0).\n",
    "plt.ylabel(\"$y$\", rotation=0)\n",
    "\n",
    "# Adiciona uma legenda ao gr√°fico, posicionada na parte superior central.\n",
    "plt.legend(loc=\"upper center\", fontsize=16)\n",
    "\n",
    "# Define o t√≠tulo para o gr√°fico da esquerda, indicando a profundidade m√°xima da √°rvore.\n",
    "plt.title(\"max_depth=2\")\n",
    "\n",
    "# Seleciona o segundo eixo (gr√°fico da direita) para plotagem.\n",
    "plt.sca(axes[1])\n",
    "\n",
    "# Extrai os thresholds correspondentes √†s divis√µes adicionais feitas pelo modelo com maior profundidade.\n",
    "# Aqui usamos a √°rvore tree_reg2, treinada com max_depth=3.\n",
    "# S√£o extra√≠dos os thresholds dos n√≥s de √≠ndices 2, 5, 9 e 12, que correspondem a divis√µes adicionais.\n",
    "th2s = tree_reg2.tree_.threshold[[2, 5, 9, 12]]\n",
    "\n",
    "# Plota as previs√µes do modelo tree_reg2 (mais profundo) e os dados reais no segundo gr√°fico.\n",
    "plot_regression_predictions(tree_reg2, X_quad, y_quad)\n",
    "\n",
    "# Plota novamente as divis√µes feitas pelo modelo anterior (com profundidade m√°xima = 2).\n",
    "# Isso permite comparar visualmente as divis√µes antigas com as novas.\n",
    "# Para cada split (limiar de divis√£o) e estilo de linha correspondente:\n",
    "# th0 ‚Üí divis√£o raiz com linha preta cont√≠nua (\"k-\")\n",
    "# th1a e th1b ‚Üí divis√µes secund√°rias com linha preta tracejada (\"k--\")\n",
    "for split, style in ((th0, \"k-\"), (th1a, \"k--\"), (th1b, \"k--\")):\n",
    "    # Desenha uma linha vertical em cada split, do y=-0.05 at√© y=0.25.\n",
    "    # Essas linhas indicam as fronteiras de decis√£o antigas.\n",
    "    plt.plot([split, split], [-0.05, 0.25], style, linewidth=2)\n",
    "\n",
    "# Plota as novas divis√µes feitas pelo modelo mais profundo.\n",
    "# Cada split em th2s representa uma nova fronteira de decis√£o.\n",
    "for split in th2s:\n",
    "    # Desenha uma linha vertical em cada novo split.\n",
    "    # Estilo \"k:\" ‚Üí linha preta (\"k\") com estilo pontilhado (\":\").\n",
    "    # linewidth=1 ‚Üí linha mais fina que as anteriores.\n",
    "    plt.plot([split, split], [-0.05, 0.25], \"k:\", linewidth=1)\n",
    "\n",
    "\n",
    "# Adiciona texto explicativo indicando uma das divis√µes feitas na profundidade 2.\n",
    "# Isso ilustra que o modelo mais profundo realiza divis√µes adicionais.\n",
    "plt.text(th2s[2] + 0.01, 0.15, \"Depth=2\", fontsize=13)\n",
    "\n",
    "# Define o t√≠tulo do segundo gr√°fico, indicando a maior profundidade utilizada.\n",
    "plt.title(\"max_depth=3\")\n",
    "\n",
    "# Define o caminho completo do arquivo de sa√≠da, utilizando o diret√≥rio especificado por output_dir,\n",
    "# e nomeando o arquivo como \"grafico_regress_tree.png\".\n",
    "output_path = os.path.join(output_dir, \"grafico_regress_tree.png\")\n",
    "\n",
    "# Salva a figura contendo os dois gr√°ficos no caminho especificado.\n",
    "# dpi=300 garante alta resolu√ß√£o.\n",
    "# bbox_inches='tight' remove espa√ßos em branco desnecess√°rios ao redor da figura.\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Exibe a figura na tela com os dois gr√°ficos lado a lado.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73dd56",
   "metadata": {},
   "source": [
    ">‚úÖ **O que o gr√°fico mostra:**\n",
    "\n",
    "- Eixo X (x‚ÇÅ): vari√°vel de entrada.\n",
    "\n",
    "- Eixo Y (y): vari√°vel de sa√≠da (observada e prevista).\n",
    "\n",
    "- Pontos azuis: dados observados.\n",
    "\n",
    "- Linha vermelha (≈∑): previs√£o do modelo ‚Äî valores constantes por regi√µes.\n",
    "\n",
    "- Linhas verticais: divis√µes feitas pela √°rvore:\n",
    "\n",
    "    - S√≥lida: raiz (profundidade 0).\n",
    "\n",
    "    - Tracejadas: profundidade 1.\n",
    "\n",
    "    - Pontilhadas: profundidade 2 (somente no segundo gr√°fico).\n",
    "\n",
    ">‚úÖ **Primeiro gr√°fico (esquerda, max_depth = 2):**\n",
    "A √°rvore divide os dados em at√© 3 regi√µes: uma divis√£o principal e duas subsequentes. O modelo prev√™ valores constantes em cada regi√£o, gerando uma linha \"em degraus\". √â uma aproxima√ß√£o simples, com baixo risco de overfitting, mas poss√≠vel underfitting.\n",
    "\n",
    ">‚úÖ **Segundo gr√°fico (direita, max_depth = 3):**\n",
    "Com mais profundidade, a √°rvore cria divis√µes adicionais, aumentando os \"degraus\" e melhorando o ajuste aos dados. A previs√£o fica mais detalhada, mas h√° maior risco de overfitting.\n",
    "\n",
    ">‚úÖ **Interpreta√ß√£o das divis√µes:**\n",
    "Cada linha vertical representa uma decis√£o bin√°ria da √°rvore: \"x‚ÇÅ √© menor ou maior que certo limiar?\". As divis√µes mais profundas refinam as previs√µes, mas aumentam a complexidade e o risco de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87759bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma figura com tamanho maior para que a √°rvore fique leg√≠vel.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Usamos a fun√ß√£o plot_tree para desenhar a √°rvore de decis√£o treinada.\n",
    "plot_tree(\n",
    "    tree_reg2,            # O modelo de √°rvore de decis√£o j√° treinado.\n",
    "    feature_names=[\"x1\"],# O nome da vari√°vel de entrada, que ser√° exibido nos n√≥s da √°rvore.\n",
    "    rounded=True,        # Deixa os cantos das caixas arredondados para uma visualiza√ß√£o mais est√©tica.\n",
    "    filled=True,         # Preenche os n√≥s com cores representando a escala dos valores previstos.\n",
    "    impurity=True,       # Mostra a impureza (SSE) de cada n√≥.\n",
    "    precision=3          # Define a quantidade de casas decimais exibidas nos valores.\n",
    ")\n",
    "\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"decision_tree_plot_4.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Exibimos o gr√°fico na tela.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b246469",
   "metadata": {},
   "source": [
    ">VAMOS FAZER MANUALMENTE UMA √ÅRVORE DE DECIS√ÇO DE REGRESS√ÉO\n",
    "\n",
    "| Inst√¢ncia | x1 | x2 | y  |\n",
    "| --------- | -- | -- | -- |\n",
    "| 1         | 1  | 0.2  | 4.5 |\n",
    "| 2         | 1.5  | 0.4  | 5 |\n",
    "| 3         | 2  | 0.6  | 5.5 |\n",
    "| 4         | 2.5  | 0.8  | 6 |\n",
    "| 5         | 3  | 1  | 6.5 |\n",
    "| 6         | 3.5  | 1.2  | 7 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0495a1",
   "metadata": {},
   "source": [
    "## **Teste e Valida√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435e2f6",
   "metadata": {},
   "source": [
    "### Testando e Validando Modelos\n",
    "\n",
    "A √∫nica forma de saber qu√£o bem um modelo ir√° generalizar para novos casos √© testando-o efetivamente em dados que ele nunca viu antes. Uma maneira √© colocar o modelo em produ√ß√£o e monitorar seu desempenho, mas isso pode ser arriscado: se o modelo for muito ruim, os usu√°rios ir√£o reclamar.\n",
    "\n",
    "Uma abordagem mais segura √© dividir os dados em dois conjuntos: **treinamento** e **teste**. Como os nomes indicam, voc√™ treina o modelo no conjunto de treinamento e testa seu desempenho no conjunto de teste. O erro que o modelo comete em novos dados √© chamado de **erro de generaliza√ß√£o** (ou erro fora da amostra). Avaliar o modelo no conjunto de teste fornece uma estimativa desse erro, indicando o qu√£o bem o modelo pode performar em dados in√©ditos.\n",
    "\n",
    "Se o erro no conjunto de treinamento for baixo, mas o erro de generaliza√ß√£o for alto, isso indica que o modelo est√° **overfittando** ‚Äî ou seja, est√° ajustado demais aos dados de treino e n√£o generaliza bem.\n",
    "\n",
    "> **Dica:** √© comum usar 80% dos dados para treino e reservar 20% para teste. No entanto, isso depende do tamanho do conjunto de dados. Por exemplo, com 10 milh√µes de inst√¢ncias, segurar apenas 1% para teste j√° fornece uma base grande o suficiente para uma boa estimativa do erro de generaliza√ß√£o.\n",
    "\n",
    "### Ajuste de Hiperpar√¢metros e Sele√ß√£o de Modelo\n",
    "\n",
    "Avaliar um modelo usando apenas o conjunto de teste √© simples, mas pode ser insuficiente quando h√° d√∫vida entre dois modelos diferentes (por exemplo, um modelo linear e outro polinomial). Uma estrat√©gia √© treinar ambos e comparar seu desempenho no conjunto de teste.\n",
    "\n",
    "Mas e se quisermos ajustar hiperpar√¢metros para evitar overfitting? Uma abordagem seria testar v√°rias combina√ß√µes desses hiperpar√¢metros e escolher a que apresentar melhor desempenho no conjunto de teste.\n",
    "\n",
    "Por√©m, isso pode levar a um problema chamado **vazamento de teste**: ao otimizar hiperpar√¢metros repetidamente usando o conjunto de teste, o modelo fica \"ajustado\" para esse conjunto espec√≠fico, e seu desempenho em dados realmente novos pode ser pior do que o esperado.\n",
    "\n",
    "### Valida√ß√£o Hold-out\n",
    "\n",
    "Uma solu√ß√£o para esse problema √© a **valida√ß√£o hold-out**: dentro do conjunto de treinamento, reservamos uma parte para valida√ß√£o, chamada de conjunto de **valida√ß√£o** (ou conjunto de desenvolvimento - dev set). Assim, o processo fica assim:\n",
    "\n",
    "- Treina-se v√°rios modelos com diferentes hiperpar√¢metros no conjunto de treino reduzido (excluindo o conjunto de valida√ß√£o).\n",
    "- Avalia-se o desempenho de cada modelo no conjunto de valida√ß√£o.\n",
    "- Seleciona-se o melhor modelo conforme o desempenho na valida√ß√£o.\n",
    "- Treina-se o modelo final usando todo o conjunto de treinamento (treino + valida√ß√£o).\n",
    "- Avalia-se o modelo final no conjunto de teste para estimar o erro de generaliza√ß√£o.\n",
    "\n",
    "Essa t√©cnica geralmente funciona bem, mas h√° um equil√≠brio importante:  \n",
    "- Se o conjunto de valida√ß√£o for pequeno demais, a avalia√ß√£o pode ser imprecisa e podemos escolher um modelo sub√≥timo.  \n",
    "- Se o conjunto de valida√ß√£o for muito grande, o conjunto de treino fica pequeno, e o modelo final pode ficar prejudicado por ter menos dados para aprender.\n",
    "\n",
    "### Valida√ß√£o K-Fold\n",
    "\n",
    "Para contornar essas limita√ß√µes, usa-se a **valida√ß√£o cruzada K-Fold**. Nessa t√©cnica:\n",
    "\n",
    "- O conjunto de dados √© dividido em *K* partes (folds) de tamanho similar.\n",
    "- O modelo √© treinado *K* vezes, cada vez deixando um fold diferente para valida√ß√£o e usando os outros *K-1* folds para treino.\n",
    "- A performance do modelo √© avaliada em cada fold de valida√ß√£o, e a m√©dia dessas avalia√ß√µes d√° uma estimativa mais robusta do desempenho.\n",
    "\n",
    "Assim, conseguimos aproveitar melhor os dados, usando v√°rios conjuntos pequenos de valida√ß√£o, e temos uma medida mais precisa do erro de generaliza√ß√£o. A desvantagem √© o custo computacional maior, pois o modelo precisa ser treinado *K* vezes.\n",
    "\n",
    "---\n",
    "\n",
    "**Resumo:**  \n",
    "- **Hold-out:** simples, divide o dado em treino, valida√ß√£o e teste. Pode ser inst√°vel se os conjuntos forem pequenos.  \n",
    "- **K-Fold:** usa m√∫ltiplas divis√µes para melhorar a estimativa do desempenho, com maior custo computacional.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72484fde",
   "metadata": {},
   "source": [
    "### Introdu√ß√£o √° Acur√°cia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe17de",
   "metadata": {},
   "source": [
    "A **acur√°cia** √© uma m√©trica que indica a **propor√ß√£o de acertos** de um modelo de classifica√ß√£o sobre o total de previs√µes realizadas.\n",
    "\n",
    "#### ‚û°Ô∏è Defini√ß√£o matem√°tica:\n",
    "\n",
    "$$\n",
    "\\text{Acur√°cia} = \\dfrac{\\text{N√∫mero de previs√µes corretas}}{\\text{Total de previs√µes}}\n",
    "$$\n",
    "\n",
    "Ou, de forma mais formal:\n",
    "\n",
    "$$\n",
    "\\text{Acur√°cia} = \\dfrac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Onde:  \n",
    "- **TP** = Verdadeiros Positivos  \n",
    "- **TN** = Verdadeiros Negativos  \n",
    "- **FP** = Falsos Positivos  \n",
    "- **FN** = Falsos Negativos  \n",
    "\n",
    "---\n",
    "\n",
    "##### ‚úÖ Qual √© a fun√ß√£o da Acur√°cia?\n",
    "\n",
    "- Medir a **efici√™ncia global** do modelo.\n",
    "- Verificar a **propor√ß√£o de acertos** em todas as classes.\n",
    "- Muito utilizada como uma **m√©trica simples e direta** de avalia√ß√£o.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö†Ô∏è Limita√ß√µes da Acur√°cia\n",
    "\n",
    "- **Problemas com classes desbalanceadas**: quando uma classe √© muito mais frequente que outra, a acur√°cia pode ser **enganosa**.\n",
    "  \n",
    "  Exemplo:  \n",
    "  Se 95% dos dados s√£o da Classe A, um modelo que sempre prev√™ \"A\" ter√° 95% de acur√°cia ‚Äî mas √© um **modelo in√∫til**.\n",
    "\n",
    "- **N√£o informa sobre erros espec√≠ficos**: n√£o diferencia se o modelo erra mais positivos ou negativos.\n",
    "\n",
    "- **N√£o captura nuances** como:\n",
    "  - Precis√£o (Precision)\n",
    "  - Revoca√ß√£o (Recall)\n",
    "  - F1-Score\n",
    "\n",
    "Por isso, √© recomendada a an√°lise conjunta com outras m√©tricas, principalmente em problemas **desbalanceados**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ A acur√°cia serve s√≥ para classifica√ß√£o bin√°ria?\n",
    "\n",
    "**N√£o!**  \n",
    "A acur√°cia pode ser utilizada tanto para:\n",
    "\n",
    "- **Classifica√ß√£o bin√°ria**: dois r√≥tulos (Ex.: \"doente\" ou \"saud√°vel\").\n",
    "- **Classifica√ß√£o multiclasse**: m√∫ltiplos r√≥tulos (Ex.: \"setosa\", \"versicolor\", \"virginica\").\n",
    "\n",
    "Em problemas multiclasse, a acur√°cia continua sendo:  \n",
    "$$\n",
    "\\dfrac{\\text{Total de acertos}}{\\text{Total de exemplos}}\n",
    "$$\n",
    "\n",
    "##### ‚ö†Ô∏è Observa√ß√£o importante:\n",
    "\n",
    "Em problemas multiclasse, principalmente com **classes desbalanceadas** ou **classes raras**, a acur√°cia pode ser ainda **menos confi√°vel**.  \n",
    "\n",
    "Por isso, √© recomend√°vel tamb√©m usar m√©tricas como:  \n",
    "- **Matriz de Confus√£o Multiclasse**  \n",
    "- **Macro/Micro F1-Score**  \n",
    "- **Balanced Accuracy**  \n",
    "\n",
    "Essas m√©tricas ajudam a **entender melhor o desempenho** em cada classe.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Resumo\n",
    "\n",
    "‚úîÔ∏è Acur√°cia: **m√©trica geral**, simples e intuitiva.  \n",
    "‚úîÔ∏è Serve para **bin√°rio e multiclasse**.  \n",
    "‚ùå N√£o √© suficiente sozinha em **casos desbalanceados**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86549c5",
   "metadata": {},
   "source": [
    "### **Hold-out Cross-Validation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d556b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a base de dados Iris do scikit-learn\n",
    "iris = load_iris()\n",
    "X = iris.data[:, [0, 1]]  # Usamos apenas as features 0 e 1\n",
    "y = iris.target    # R√≥tulos/classes correspondentes (tipo da flor)\n",
    "# ‚úÖ Transformar o problema em bin√°rio: Setosa (1) ou n√£o (0)\n",
    "y = (y == 0).astype(int)\n",
    "\n",
    "# Passo 1: Separar o conjunto de teste (20% dos dados totais)\n",
    "# train_test_split divide os dados em dois conjuntos:\n",
    "# - X_train_val, y_train_val: que ser√£o usados para treino e valida√ß√£o\n",
    "# - X_test, y_test: usados apenas para testar o modelo final\n",
    "# Par√¢metros:\n",
    "# test_size=0.2 indica que 20% dos dados v√£o para o teste\n",
    "# random_state=42 garante que a divis√£o seja reprodut√≠vel (sempre a mesma)\n",
    "# stratify=y mant√©m a distribui√ß√£o original das classes/labels nos conjuntos divididos\n",
    "# \n",
    "# Sobre o stratify:\n",
    "# - Aceita: arrays de valores categ√≥ricos (classes) ou num√©ricos discretos (como inteiros)\n",
    "# - Para classifica√ß√£o: ideal para problemas com classes desbalanceadas, preserva a propor√ß√£o\n",
    "#   de cada classe nos conjuntos de treino e teste\n",
    "# - Para regress√£o: normalmente n√£o usado, mas pode ser aplicado se:\n",
    "#   1. Converter o target cont√≠nuo em bins discretos (ex: quartis, decis)\n",
    "#   2. Usar esses bins como estratos\n",
    "# - Quando y √© None, stratify √© ignorado\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Passo 2: Separar treino e valida√ß√£o dentro dos 80% restantes (X_train_val e y_train_val)\n",
    "# Aqui vamos separar 20% desse conjunto para valida√ß√£o, ou seja,\n",
    "# 20% dos 80% = 16% do total dos dados\n",
    "# Isso cria tr√™s conjuntos finais:\n",
    "# - treino: para ajustar o modelo\n",
    "# - valida√ß√£o: para ajustar hiperpar√¢metros e selecionar modelos\n",
    "# - teste: para avalia√ß√£o final e estimativa do erro de generaliza√ß√£o\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os tamanhos dos conjuntos para conferir se a divis√£o est√° correta\n",
    "print(f\"Tamanho treino: {X_train.shape[0]} amostras\")      # Aproximadamente 64% do total\n",
    "print(f\"Tamanho valida√ß√£o: {X_val.shape[0]} amostras\")     # Aproximadamente 16% do total\n",
    "print(f\"Tamanho teste: {X_test.shape[0]} amostras\")        # Exatamente 20% do total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39090660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo sem restri√ß√£o de profundidade\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calcular acur√°cias nos tr√™s conjuntos\n",
    "train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "val_accuracy = accuracy_score(y_val, clf.predict(X_val))\n",
    "test_accuracy = accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516107d",
   "metadata": {},
   "source": [
    "**Nota:** `accuracy_score()` √© uma fun√ß√£o pronta do *Sklearn* que me retorna a acur√°cia de forma autom√°tica, seus par√¢metros s√£o:\n",
    "\n",
    "- **`y_true`**: array-like de forma (n_samples)  \n",
    "  Valores reais das classes.\n",
    "\n",
    "- **`y_pred`**: array-like de forma (n_samples)  \n",
    "  Valores previstos pelo modelo.\n",
    "\n",
    "- **`normalize`**: bool, default=`True`  \n",
    "  - Se `True`, retorna a fra√ß√£o de previs√µes corretas (acur√°cia).  \n",
    "  - Se `False`, retorna o n√∫mero absoluto de previs√µes corretas.\n",
    "\n",
    "- **`sample_weight`**: array-like de forma (n_samples), default=`None`  \n",
    "  Permite atribuir pesos diferentes para cada amostra ao calcular a acur√°cia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414afbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o que plota diretamente a fronteira de decis√£o de um classificador\n",
    "def plot_decision_boundary_direct(clf, X, y, title, accuracy, axes=[4, 8, 1.5, 5]):\n",
    "    \"\"\"\n",
    "    Plota a fronteira de decis√£o de um classificador.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - clf: classificador treinado.\n",
    "    - X: conjunto de dados de entrada (2 features).\n",
    "    - y: r√≥tulos/classes correspondentes.\n",
    "    - title: t√≠tulo do gr√°fico.\n",
    "    - accuracy: acur√°cia que ser√° exibida no t√≠tulo.\n",
    "    - axes: limites dos eixos [x_min, x_max, y_min, y_max].\n",
    "    \"\"\"\n",
    "\n",
    "    # Gera 100 pontos igualmente espa√ßados entre os limites de cada eixo\n",
    "    x0s = np.linspace(axes[0], axes[1], 100)  # Eixo X (comprimento da p√©tala)\n",
    "    x1s = np.linspace(axes[2], axes[3], 100)  # Eixo Y (largura da p√©tala)\n",
    "\n",
    "    # Cria uma grade de coordenadas (meshgrid) combinando os valores de X e Y\n",
    "    x0, x1 = np.meshgrid(x0s, x1s)\n",
    "\n",
    "    # Empacota os pontos da grade em um array de pares (N, 2) para fazer previs√µes\n",
    "    X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "    # Classificador faz a previs√£o das classes para cada ponto da grade\n",
    "    y_pred = clf.predict(X_new)\n",
    "\n",
    "    # Ajusta as previs√µes para o formato da grade\n",
    "    zz = y_pred.reshape(x0.shape)\n",
    "\n",
    "    # Desenha a fronteira de decis√£o com √°reas coloridas (contorno preenchido)\n",
    "    plt.contourf(x0, x1, zz, cmap=plt.cm.Pastel1, alpha=0.3)\n",
    "\n",
    "    # Desenha as linhas de contorno entre as classes\n",
    "    plt.contour(x0, x1, zz, colors='k', linewidths=0.5, alpha=0.6)\n",
    "\n",
    "    # Defini√ß√£o dos r√≥tulos das classes para o problema bin√°rio\n",
    "    class_labels = {0: \"N√£o Setosa\", 1: \"Setosa\"}\n",
    "\n",
    "    # Plota os pontos reais do conjunto de dados, diferenciando por classe\n",
    "    for idx, color, marker in zip(np.unique(y), ['red', 'blue'], ['o', 's']):\n",
    "        # Para cada classe √∫nica em y:\n",
    "        # - idx: valor da classe\n",
    "        # - color: cor associada\n",
    "        # - marker: marcador associado\n",
    "        # Seleciona as amostras pertencentes √† classe atual (y == idx)\n",
    "        # Plota essas amostras com a cor e o marcador especificados\n",
    "        plt.scatter(\n",
    "            X[y == idx, 0],           # Coordenada x das amostras da classe\n",
    "            X[y == idx, 1],           # Coordenada y das amostras da classe\n",
    "            c=color,                  # Cor do ponto\n",
    "            label=class_labels[idx],  # R√≥tulo da classe (para a legenda)\n",
    "            marker=marker,            # Formato do marcador\n",
    "            edgecolor='k'             # Cor da borda do ponto (preta)\n",
    "        )\n",
    "\n",
    "\n",
    "    # Configura os r√≥tulos e t√≠tulo do gr√°fico\n",
    "    plt.xlabel(\"Petal length (cm)\")\n",
    "    plt.ylabel(\"Petal width (cm)\")\n",
    "    plt.title(f\"{title}\\nAcur√°cia: {accuracy:.4f}\")\n",
    "\n",
    "    # Define os limites dos eixos conforme especificado\n",
    "    plt.xlim(axes[0], axes[1])\n",
    "    plt.ylim(axes[2], axes[3])\n",
    "\n",
    "    # Adiciona legenda para identificar as classes\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gera√ß√£o dos gr√°ficos com layout 2x2 ---\n",
    "\n",
    "# Cria uma nova figura com tamanho apropriado\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# --- Gr√°fico 1: Treinamento ---\n",
    "plt.subplot(2, 2, 1)  # Posi√ß√£o 1 no grid 2x2\n",
    "plot_decision_boundary_direct(clf, X_train, y_train, \"Treinamento\", train_accuracy)\n",
    "\n",
    "# --- Gr√°fico 2: Valida√ß√£o ---\n",
    "plt.subplot(2, 2, 2)  # Posi√ß√£o 2 no grid 2x2\n",
    "plot_decision_boundary_direct(clf, X_val, y_val, \"Valida√ß√£o\", val_accuracy)\n",
    "\n",
    "# Ajusta o espa√ßamento entre os gr√°ficos\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibe todos os gr√°ficos\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad6838",
   "metadata": {},
   "source": [
    "### **K-fold Cross-Validation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65775ccb",
   "metadata": {},
   "source": [
    "√Äs vezes, precisamos de mais controle sobre o processo de valida√ß√£o cruzada do que o que o Scikit-Learn oferece pronto para uso. Nesses casos, podemos implementar a valida√ß√£o cruzada manualmente. O c√≥digo a seguir faz, aproximadamente, a mesma coisa que a fun√ß√£o `cross_val_score()` do Scikit-Learn e imprime o mesmo resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea12ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Carregar e preparar o dataset Iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:, [0, 1]]  # Usamos apenas as features 0 e 1\n",
    "feature_names = [iris.feature_names[0], iris.feature_names[1]]\n",
    "y = iris.target\n",
    "\n",
    "# ‚úÖ Transformar o problema em bin√°rio: Setosa (1) ou n√£o (0)\n",
    "y_binary = (y == 0).astype(int)\n",
    "\n",
    "# ‚úÖ Dividir o dataset em treino (90%) e teste (10%) com estratifica√ß√£o\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.1, random_state=42, stratify=y_binary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"\"\"\n",
    "Propor√ß√£o da amostra de treino e teste:\n",
    "- Treino: 90% dos dados - {len(X_train)} inst√¢ncias\n",
    "- Teste: 10% dos dados - {len(X_test)} inst√¢ncias                 \n",
    "                 \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Inicializar o classificador\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ‚úÖ Configurar valida√ß√£o cruzada estratificada para o conjunto de teste\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417eab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Loop que realiza a valida√ß√£o cruzada manual **no conjunto de treino e valida√ß√£o**\n",
    "for fold, (train_index, val_index) in enumerate(skfolds.split(X_train, y_train), 1):\n",
    "\n",
    "    # ‚úÖ Clonar o classificador para que cada fold seja treinado de forma independente\n",
    "    clone_clf = clone(tree_clf)\n",
    "\n",
    "    # ‚úÖ Separar os dados e r√≥tulos para treino e valida√ß√£o do fold atual\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # ‚úÖ Treinar o classificador na parte de treino deste fold\n",
    "    clone_clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # ‚úÖ Fazer a predi√ß√£o no fold de valida√ß√£o\n",
    "    y_pred = clone_clf.predict(X_val_fold)\n",
    "\n",
    "    # ‚úÖ Calcular a acur√°cia deste fold\n",
    "    n_correct = np.sum(y_pred == y_val_fold)\n",
    "    accuracy = n_correct / len(y_pred)\n",
    "\n",
    "    # ‚úÖ Mostrar a acur√°cia deste fold\n",
    "    print(f\"Fold {fold}: acur√°cia = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c06c45",
   "metadata": {},
   "source": [
    ">E se quisermos armazenar os par√¢metros aprendidos pelo nosso modelo e usar eles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ed35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Sele√ß√£o de duas features: comprimento e largura da s√©pala\n",
    "X = iris.data[:, [0, 1]]  # Pega as features 0 (sepal length) e 1 (sepal width)\n",
    "feature_names = [iris.feature_names[0], iris.feature_names[1]]  # Nomes das features selecionadas\n",
    "\n",
    "# R√≥tulos/classes do dataset: 0 (setosa), 1 (versicolor), 2 (virginica)\n",
    "y = iris.target\n",
    "\n",
    "# ‚úÖ Transformar o problema em bin√°rio:\n",
    "# A tarefa ser√° classificar se a flor √© da classe 0 (setosa) ou n√£o.\n",
    "# Resultado: y_binary ter√° 1 para setosa e 0 para as outras classes.\n",
    "y_binary = (y == 0).astype(int)\n",
    "\n",
    "# ‚úÖ Dividir os dados em treino e teste (90% treino, 10% teste)\n",
    "# Utilizamos stratify=y_binary para manter a mesma propor√ß√£o de classes nos dois conjuntos.\n",
    "# random_state garante reprodutibilidade.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.1, random_state=42, stratify=y_binary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dad168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Inicializar o modelo: √°rvore de decis√£o\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# ‚úÖ Configurar valida√ß√£o cruzada estratificada\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098ed21",
   "metadata": {},
   "source": [
    "Criamos um pacote que plota os gr√°ficos de Grafo e Fronteira de Decis√£o, vale mais apena automatizar um pouco do que fazer manualmente. O c√≥digo a seguir faz isso, mas voc√™ pode fazer manualmente se preferir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_plot\n",
    "from tree_plot import plot_decision_tree, plot_classification_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91071504",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []           # Para armazenar acur√°cia de cada fold\n",
    "models = []               # Para armazenar o modelo treinado de cada fold\n",
    "\n",
    "# ‚úÖ Loop de valida√ß√£o cruzada no conjunto de treino\n",
    "for fold, (train_index, val_index) in enumerate(skfolds.split(X_train, y_train), 1):\n",
    "\n",
    "    # ‚úÖ Criar c√≥pia do classificador\n",
    "    clone_clf = clone(tree_clf)\n",
    "\n",
    "    # ‚úÖ Separar dados de treino e valida√ß√£o deste fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # ‚úÖ Treinar modelo\n",
    "    clone_clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # ‚úÖ Avalia√ß√£o no conjunto de valida√ß√£o\n",
    "    y_val_pred = clone_clf.predict(X_val_fold)\n",
    "    val_accuracy = np.mean(y_val_pred == y_val_fold)\n",
    "    \n",
    "    accuracies.append(val_accuracy)\n",
    "    models.append(clone_clf)  # ‚úÖ Guardar modelo treinado\n",
    "\n",
    "    # ‚úÖ Plotar √°rvore de decis√£o\n",
    "    plot_decision_tree(\n",
    "        model=clone_clf,\n",
    "        feature_names=feature_names,  \n",
    "        class_names=[\"Outras Plantas\", \"Setosa\"],  \n",
    "        title=f\"√Årvore de Decis√£o - Fold {fold}\",\n",
    "        output_path=None,\n",
    "        show=True\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Mostrar a acur√°cia como Markdown logo ap√≥s a √°rvore\n",
    "    display(Markdown(f\"**Fold {fold} - Acur√°cia de Valida√ß√£o:** {val_accuracy:.4f}\"))\n",
    "\n",
    "    # ‚úÖ Plotar fronteira de decis√£o usando conjunto de valida√ß√£o\n",
    "    plot_classification_decision_boundary(\n",
    "        model=clone_clf,\n",
    "        X=X_val_fold,  # Visualiza√ß√£o sobre o conjunto de VALIDA√á√ÉO\n",
    "        y=y_val_fold,\n",
    "        feature_names=feature_names,\n",
    "        class_names=[\"Outras Plantas\", \"Setosa\"],\n",
    "        title=f\"Fronteira de Decis√£o (Valida√ß√£o) - Fold {fold}\",\n",
    "        output_path=None,\n",
    "        show=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f797b",
   "metadata": {},
   "source": [
    "A classe **StratifiedKFold** realiza uma amostragem estratificada (conforme explicado no antes) para produzir folds que contenham uma propor√ß√£o representativa de cada classe. Em cada itera√ß√£o, o c√≥digo cria uma c√≥pia (clone) do classificador, treina essa c√≥pia nos folds de treinamento e faz previs√µes no fold de valida√ß√£o. Em seguida, conta o n√∫mero de previs√µes corretas e exibe a propor√ß√£o dessas previs√µes corretas.\n",
    "\n",
    "Vamos visualizar (gr√°fico de gr√°fos e de limites) os diferentes modelos com suas respectivas acur√°cias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Selecionar o √≠ndice do modelo com melhor acur√°cia\n",
    "best_index = np.argmax(accuracies)\n",
    "best_model = models[best_index]\n",
    "\n",
    "display(Markdown(f\"### ‚úÖ Melhor modelo: Fold {best_index + 1} com acur√°cia de valida√ß√£o = {accuracies[best_index]:.4f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e84173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Usa o modelo final (best_model) para gerar previs√µes no conjunto de teste.\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# ‚úÖ Calcula a acur√°cia: propor√ß√£o de previs√µes corretas no conjunto de teste.\n",
    "# np.mean(y_test_pred == y_test) compara elemento a elemento os r√≥tulos previstos com os verdadeiros,\n",
    "# gerando um array booleano (True para acertos, False para erros).\n",
    "# np.mean converte True para 1 e False para 0, retornando a m√©dia: acur√°cia.\n",
    "test_accuracy = np.mean(y_test_pred == y_test)\n",
    "\n",
    "# ‚úÖ Mostra a acur√°cia em formato Markdown, com destaque visual no Jupyter Notebook.\n",
    "display(Markdown(f\"### ‚úÖ **Acur√°cia** no conjunto de **teste** com o melhor modelo: {test_accuracy*100}% de Acur√°cia\"))\n",
    "\n",
    "# ‚úÖ Plota a fronteira de decis√£o do modelo no conjunto de teste.\n",
    "# Isso permite visualizar como o modelo separa as classes nesse subconjunto.\n",
    "plot_classification_decision_boundary(\n",
    "    model=best_model,            # modelo treinado e ajustado\n",
    "    X=X_test,                    # conjunto de teste (features)\n",
    "    y=y_test,                    # conjunto de teste (r√≥tulos)\n",
    "    feature_names=feature_names, # nomes das features para rotular os eixos\n",
    "    class_names=[\"Outras Plantas\", \"Setosa\"], # nomes das classes\n",
    "    title=\"Fronteira de Decis√£o - Melhor Modelo no Conjunto de TESTE\", # t√≠tulo do gr√°fico\n",
    "    output_path=None,            # n√£o salva, apenas exibe\n",
    "    show=True                    # exibe o gr√°fico na tela\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec5738",
   "metadata": {},
   "source": [
    ">Por√©m, poderiamos usar o cl√°ssico metodo de valida√ß√£o cruzada chamado ``cross_val_score()``, do *Sklearn* que j√° aplica a valida√ß√£o cruzada por *K-Fold* automaticamente.\n",
    "\n",
    "##### Para que serve `cross_val_score()`?\n",
    "\n",
    "* **Avalia√ß√£o Robusta:** Fornece uma estimativa mais confi√°vel do desempenho de um modelo em dados n√£o vistos, pois o modelo √© treinado e testado em diferentes subconjuntos dos dados.\n",
    "* **Detec√ß√£o de Overfitting/Underfitting:** Ajuda a identificar se o modelo est√° memorizando os dados de treino (*overfitting*) ou se n√£o est√° aprendendo o suficiente (*underfitting*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Nota: A divis√£o com train_test_split n√£o ser√° usada diretamente pelo cross_val_score,\n",
    "# mas √© √∫til para entender como seus dados s√£o geralmente divididos.)\n",
    "# ‚úÖ Dividir o dataset em treino (90%) e teste (10%) com estratifica√ß√£o\n",
    "# (Seu exemplo usou test_size=0.1, aqui mantemos assim para consist√™ncia)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.1, random_state=21, stratify=y_binary\n",
    ")\n",
    "\n",
    "# ‚úÖ Inicializar o classificador\n",
    "tree_clf_cv = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39476b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aplica√ß√£o do cross_val_score() ---\n",
    "\n",
    "# Realizar valida√ß√£o cruzada com 3 folds (cv=3)\n",
    "# Por padr√£o, usa StratifiedKFold para classificadores.\n",
    "scores = cross_val_score(estimator=tree_clf_cv,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=3,      # N√∫mero de folds (dobras) para a valida√ß√£o cruzada\n",
    "                         scoring='accuracy') # M√©trica de avalia√ß√£o (pode ser 'f1', 'precision', etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c05df",
   "metadata": {},
   "source": [
    "##### Explica√ß√£o dos Par√¢metros de `cross_val_score()`:\n",
    "\n",
    "* **`estimator`**: √â o objeto do **modelo** (classificador ou regressor) que voc√™ deseja avaliar. No seu caso, `tree_clf`. O `cross_val_score()` ir√° clonar este estimador para cada *fold*, trein√°-lo e avali√°-lo.\n",
    "\n",
    "* **`X`**: O conjunto de dados de **features** (caracter√≠sticas) de entrada. No seu exemplo, `X`.\n",
    "\n",
    "* **`y`**: O conjunto de dados das **classes-alvo**. No seu exemplo, `y_binary`.\n",
    "\n",
    "* **`cv`**: Define a **estrat√©gia de valida√ß√£o cruzada**.\n",
    "    * **N√∫mero inteiro (ex: `cv=3`)**: `cross_val_score` usar√°:\n",
    "        * `KFold` para regressores.\n",
    "        * `StratifiedKFold` para classificadores (como `DecisionTreeClassifier`), o que √© √≥timo para lidar com desbalanceamento de classes, garantindo que cada *fold* tenha propor√ß√µes de classe semelhantes √†s do conjunto de dados completo.\n",
    "    * **Objeto de Valida√ß√£o Cruzada (ex: `cv=StratifiedKFold(...)`)**: Voc√™ pode passar uma inst√¢ncia de uma classe de valida√ß√£o cruzada (como `StratifiedKFold`, `ShuffleSplit`, `StratifiedShuffleSplit`, etc.) para ter controle total sobre como as divis√µes s√£o feitas. Isso √© mais expl√≠cito e permite configurar embaralhamento (`shuffle=True`) e `random_state`.\n",
    "\n",
    "* **`scoring`**: A **m√©trica de avalia√ß√£o** a ser usada. Por padr√£o, para classificadores, √© `accuracy`. Voc√™ pode especificar outras m√©tricas como `'f1'`, `'precision'`, `'recall'`, `'roc_auc'`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7717d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"\"\"\n",
    "##### **Resultados da Valida√ß√£o Cruzada**\n",
    "\n",
    "- **Acur√°cia em cada fold:**  \n",
    "  `{scores}`\n",
    "\n",
    "- **Acur√°cia m√©dia:**  \n",
    "  `{scores.mean():.2f}`\n",
    "\n",
    "- **Desvio padr√£o da acur√°cia:**  \n",
    "  `{scores.std():.2f}`\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987efdf",
   "metadata": {},
   "source": [
    ">Se quisermos usar o modelo com melhor acur√°cia devemos usar a fun√ß√£o `cross_validate()`, a fun√ß√£o `cross_validate_score()`apenas retorna a pontua√ß√£o(m√©trica de avalia√ß√£o) do modelo para as diferentes amostras de valida√ß√£o, vamos ver como usa o `cross_validate()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo\n",
    "tree_clf_cv_ = DecisionTreeClassifier(random_state=21)\n",
    "\n",
    "# Aplicar cross_validate (retorna scores + modelos opcionalmente)\n",
    "cv_results = cross_validate(\n",
    "    estimator=tree_clf_cv_,\n",
    "    X=X_train,  # Dados de treino/valida√ß√£o (90%)\n",
    "    y=y_train,\n",
    "    cv=3,           # 3-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    return_estimator=True  # Isso guarda os modelos treinados em cada fold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75dd54",
   "metadata": {},
   "source": [
    "- `return_estimator`: √© um **par√¢metro** da fun√ß√£o `cross_validate()` do Scikit-Learn que controla se os modelos treinados em cada fold da valida√ß√£o cruzada devem ser retornados junto com as m√©tricas.\n",
    "\n",
    "    - Se `True`, retorna os modelos treinados em cada divis√£o do cross-validation.\n",
    "    - Se `False` (padr√£o), retorna apenas as m√©tricas de avalia√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver a acur√°cia de cada fold\n",
    "display(Markdown(f\"\"\"**Acur√°cias de cada fold:** `{cv_results['test_score']}`\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair os modelos treinados em cada fold\n",
    "trained_models = cv_results['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar o modelo com melhor performance (maior acur√°cia)\n",
    "best_model_idx = np.argmax(cv_results['test_score'])\n",
    "best_model_ = trained_models[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"\"\"Melhor modelo (fold `{best_model_idx + 1}`) - Acur√°cia: `{cv_results['test_score'][best_model_idx]:.4f}`\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c4ab1",
   "metadata": {},
   "source": [
    "##### Avaliar o melhor modelo no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80185263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previs√µes no teste\n",
    "y_pred = best_model_.predict(X_test)\n",
    "\n",
    "# Calcular acur√°cia no teste\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "display(Markdown(f\"\"\"Acur√°cia no teste: `{test_accuracy:.4f}`\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Mostra a acur√°cia em formato Markdown, com destaque visual no Jupyter Notebook.\n",
    "display(Markdown(f\"### ‚úÖ **Acur√°cia** no conjunto de **teste** com o melhor modelo: `{test_accuracy*100:.2f}`% de Acur√°cia\"))\n",
    "\n",
    "# ‚úÖ Plota a fronteira de decis√£o do modelo no conjunto de teste.\n",
    "# Isso permite visualizar como o modelo separa as classes nesse subconjunto.\n",
    "plot_classification_decision_boundary(\n",
    "    model=best_model_,            # modelo treinado e ajustado\n",
    "    X=X_test,                    # conjunto de teste (features)\n",
    "    y=y_test,                    # conjunto de teste (r√≥tulos)\n",
    "    feature_names=feature_names, # nomes das features para rotular os eixos\n",
    "    class_names=[\"Outras Plantas\", \"Setosa\"], # nomes das classes\n",
    "    title=\"Fronteira de Decis√£o - Melhor Modelo no Conjunto de TESTE\", # t√≠tulo do gr√°fico\n",
    "    output_path=None,            # n√£o salva, apenas exibe\n",
    "    show=True                    # exibe o gr√°fico na tela\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9f392",
   "metadata": {},
   "source": [
    "### **Regularizar**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2e9c6",
   "metadata": {},
   "source": [
    "Assim como nas tarefas de classfica√ß√£o, as √°rvores de decis√£o s√£o propensas a se **sobreajustarem** demais ao lidar com tarefas de **regress√£o**, Sem nenhuma **regulariza√ß√£o** (ou seja, usando **hiperpar√¢metros-padr√£o**) obtem-se  modelos que se ajustam muito bem aos dados de treinamento, mas que n√£o generalizam bem para novos dados. Para evitar isso, √© comum usar hiperpar√¢metros como `min_samples_leaf` para limitar o n√∫mero de amostras em cada folha da √°rvore.\n",
    "\n",
    "No c√≥digo abaixo, treinamos dois modelos de √°rvore de decis√£o para um problema de regress√£o, comparando o efeito da regulariza√ß√£o.\n",
    "\n",
    "- **Modelo 1:** √Årvore sem restri√ß√µes ‚Äî ajuste m√°ximo aos dados (tende ao **overfitting**).\n",
    "- **Modelo 2:** √Årvore regularizada com `min_samples_leaf=10` ‚Äî evita divis√µes em folhas com menos de 10 amostras, tornando o modelo mais simples e generaliz√°vel.\n",
    "\n",
    "### üîß O que √© feito:\n",
    "- Geramos uma sequ√™ncia de pontos no intervalo `[-0.5, 0.5]` para visualizar as predi√ß√µes de ambos os modelos.\n",
    "- As predi√ß√µes s√£o feitas para esses pontos usando os dois modelos.\n",
    "\n",
    "### üé® Visualiza√ß√£o:\n",
    "- Dois gr√°ficos s√£o gerados lado a lado:\n",
    "  - **Esquerda:** √°rvore sem restri√ß√µes ‚Äî a linha vermelha se ajusta exatamente aos dados (mais degraus).\n",
    "  - **Direita:** √°rvore regularizada ‚Äî a linha vermelha √© mais suave, com menos degraus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Cria√ß√£o de duas inst√¢ncias de √°rvores de regress√£o\n",
    "# A primeira √°rvore (tree_reg1) √© criada sem restri√ß√µes espec√≠ficas.\n",
    "tree_reg1 = DecisionTreeRegressor(random_state=21)  \n",
    "\n",
    "# A segunda √°rvore (tree_reg2) √© criada com regulariza√ß√£o: min_samples_leaf=10\n",
    "# Isso significa que cada folha da √°rvore deve ter pelo menos 10 amostras, evitando overfitting.\n",
    "tree_reg2 = DecisionTreeRegressor(random_state=21, min_samples_leaf=10)  \n",
    "\n",
    "# ‚úÖ Treinamento (fit) das duas √°rvores com os dados quadr√°ticos (X_quad, y_quad)\n",
    "# Sup√µe-se que X_quad e y_quad sejam arrays com a vari√°vel independente e a dependente, respectivamente.\n",
    "tree_reg1.fit(X_quad, y_quad)\n",
    "tree_reg2.fit(X_quad, y_quad)\n",
    "\n",
    "# ‚úÖ Cria√ß√£o de uma grade de valores para a vari√°vel independente\n",
    "# np.linspace cria 500 pontos igualmente espa√ßados entre -0.5 e 0.5.\n",
    "# reshape(-1, 1) transforma o array de shape (500,) para shape (500,1), necess√°rio para a predi√ß√£o.\n",
    "x1 = np.linspace(-0.5, 0.5, 500).reshape(-1, 1)\n",
    "\n",
    "# ‚úÖ Realiza√ß√£o das previs√µes com ambos os modelos treinados\n",
    "# Aqui, cada √°rvore faz previs√µes para todos os valores da grade x1.\n",
    "y_pred1 = tree_reg1.predict(x1)\n",
    "y_pred2 = tree_reg2.predict(x1)\n",
    "\n",
    "# ‚úÖ Cria√ß√£o de uma figura com dois subgr√°ficos lado a lado\n",
    "# ncols=2: duas colunas de gr√°ficos\n",
    "# figsize: tamanho total da figura (10 de largura, 4 de altura)\n",
    "# sharey=True: ambos os gr√°ficos compartilham o mesmo eixo y\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# ‚úÖ Plotagem no primeiro subgr√°fico (√† esquerda)\n",
    "\n",
    "# plt.sca define o eixo ativo para plotagem (o primeiro eixo: axes[0])\n",
    "plt.sca(axes[0])\n",
    "\n",
    "# Plotagem dos dados reais como pontos azuis\n",
    "plt.plot(X_quad, y_quad, \"b.\")\n",
    "\n",
    "# Plotagem da predi√ß√£o da √°rvore 1 como linha vermelha com pontos\n",
    "plt.plot(x1, y_pred1, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "\n",
    "# Defini√ß√£o dos limites dos eixos: x de -0.5 a 0.5, y de -0.05 a 0.25\n",
    "plt.axis([-0.5, 0.5, -0.05, 0.25])\n",
    "\n",
    "# Rotula√ß√£o do eixo x\n",
    "plt.xlabel(\"$x_1$\")\n",
    "\n",
    "# Rotula√ß√£o do eixo y, com rota√ß√£o horizontal (rotation=0)\n",
    "plt.ylabel(\"$y$\", rotation=0)\n",
    "\n",
    "# Inclus√£o de legenda no topo central do gr√°fico\n",
    "plt.legend(loc=\"upper center\")\n",
    "\n",
    "# T√≠tulo do gr√°fico indicando que n√£o h√° restri√ß√µes\n",
    "plt.title(\"Sem restri√ß√µes\")\n",
    "\n",
    "# ‚úÖ Plotagem no segundo subgr√°fico (√† direita)\n",
    "\n",
    "# Ativa√ß√£o do segundo eixo\n",
    "plt.sca(axes[1])\n",
    "\n",
    "# Repeti√ß√£o da plotagem dos dados reais\n",
    "plt.plot(X_quad, y_quad, \"b.\")\n",
    "\n",
    "# Plotagem da predi√ß√£o da segunda √°rvore (com regulariza√ß√£o)\n",
    "plt.plot(x1, y_pred2, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
    "\n",
    "# Mesmo ajuste de limites dos eixos\n",
    "plt.axis([-0.5, 0.5, -0.05, 0.25])\n",
    "\n",
    "# Rotula√ß√£o do eixo x\n",
    "plt.xlabel(\"$x_1$\")\n",
    "\n",
    "# T√≠tulo informando o par√¢metro min_samples_leaf usado\n",
    "plt.title(f\"min_samples_leaf={tree_reg2.min_samples_leaf}\")\n",
    "\n",
    "# ‚úÖ Fun√ß√£o para salvar a figura como arquivo\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"decision_tree_plot_5.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# ‚úÖ Exibi√ß√£o da figura na tela\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79644fd",
   "metadata": {},
   "source": [
    "### **Instabilidade das √Årvores de Decis√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082a8d0",
   "metadata": {},
   "source": [
    "Espero que agora voc√™ esteja convencido de que as √Årvores de Decis√£o t√™m muitas vantagens: elas s√£o simples de entender e interpretar, f√°ceis de usar, vers√°teis e poderosas. No entanto, elas t√™m algumas limita√ß√µes. Primeiro, como voc√™ pode ter notado, as √Årvores de Decis√£o adoram limites de decis√£o ortogonais (todas as divis√µes s√£o perpendiculares a um eixo), o que as torna sens√≠veis √† rota√ß√£o do conjunto de treinamento. Por exemplo, o gr√°fico abaixo mostra um conjunto de dados linearmente separ√°vel: √† esquerda, uma √Årvore de Decis√£o pode dividi-lo facilmente, enquanto √† direita, ap√≥s o conjunto ser rotacionado em 45¬∞, o limite de decis√£o parece desnecessariamente complexo. Embora ambas as √Årvores se ajustem perfeitamente aos dados de treinamento, √© prov√°vel que o modelo √† direita n√£o generalize bem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f7f98",
   "metadata": {},
   "source": [
    ">**Criando fun√ß√£o para apresentar a instabilidade:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ce8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y, axes, cmap):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para plotar a fronteira de decis√£o de um classificador 2D.\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - clf: classificador treinado (com m√©todo predict)\n",
    "    - X: dados de entrada, formato (n_amostras, 2)\n",
    "    - y: r√≥tulos das classes\n",
    "    - axes: limites dos eixos [x_min, x_max, y_min, y_max]\n",
    "    - cmap: colormap usado para as regi√µes (ex.: \"Pastel1\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # ‚úÖ Cria√ß√£o de uma malha de pontos que cobre toda a √°rea definida pelos 'axes'\n",
    "    # A fun√ß√£o np.meshgrid cria uma grade de coordenadas, √∫til para visualizar a fronteira de decis√£o.\n",
    "    x1, x2 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 100),  # Cria 100 pontos igualmente espa√ßados no eixo x, cobrindo o intervalo axes[0] at√© axes[1]\n",
    "        np.linspace(axes[2], axes[3], 100)   # Cria 100 pontos igualmente espa√ßados no eixo y, cobrindo o intervalo axes[2] at√© axes[3]\n",
    "    )\n",
    "    # Resultado: dois arrays 100x100. \n",
    "    # x1 cont√©m as coordenadas de x repetidas por linha; \n",
    "    # x2 cont√©m as coordenadas de y repetidas por coluna.\n",
    "    # Juntos representam todas as combina√ß√µes poss√≠veis de pontos no grid (100x100 = 10.000 pontos).\n",
    "\n",
    "    # ‚úÖ Empilhando os pontos da malha em um array 2D de amostras (formato: n_amostras x n_features)\n",
    "    # Isso transforma a grade em uma lista de pontos para que o modelo possa fazer a previs√£o.\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]  \n",
    "    # ravel() \"achata\" cada matriz (100x100) em um vetor de 10.000 elementos.\n",
    "    # np.c_ concatena esses vetores coluna a coluna, formando um array de shape (10000, 2).\n",
    "    # Cada linha de X_new representa um ponto (x, y) do grid.\n",
    "\n",
    "\n",
    "    # ‚úÖ Fazendo a predi√ß√£o do classificador em cada ponto da malha\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)  \n",
    "    # reshape para voltar a ter a forma de grade (100x100), para facilitar o plot\n",
    "\n",
    "    # ‚úÖ Plotando a regi√£o de decis√£o com preenchimento de cores\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=cmap)  \n",
    "    # contourf ‚Üí cria um gr√°fico de contorno preenchido:\n",
    "    # - Cada regi√£o do espa√ßo (definida pela malha x1, x2) √© colorida conforme a classe prevista (y_pred).\n",
    "    # - alpha=0.3 ‚Üí define a transpar√™ncia das cores, permitindo que outros elementos (como pontos reais) apare√ßam por cima.\n",
    "    # - cmap ‚Üí especifica o mapa de cores a ser usado para diferenciar visualmente as classes.\n",
    "\n",
    "    # ‚úÖ Plotando as linhas de contorno da fronteira de decis√£o\n",
    "    plt.contour(x1, x2, y_pred, cmap=\"Greys\", alpha=0.8)  \n",
    "    # contour ‚Üí plota apenas as linhas de contorno, ou seja, as divis√µes entre regi√µes de classes diferentes.\n",
    "    # - Isso ajuda a destacar visualmente a \"fronteira de decis√£o\" do modelo.\n",
    "    # - cmap=\"Greys\" ‚Üí utiliza tons de cinza para as linhas, criando contraste com as √°reas coloridas.\n",
    "    # - alpha=0.8 ‚Üí define a transpar√™ncia das linhas, aqui mais opacas para maior destaque.\n",
    "\n",
    "\n",
    "    # ‚úÖ Definindo as cores associadas a cada colormap\n",
    "    colors = {\n",
    "        \"Wistia\": [\"#78785c\", \"#c47b27\"],  # Exemplo de cores personalizadas\n",
    "        \"Pastel1\": [\"red\", \"blue\"]         # Cores padr√£o usadas no livro/exemplo\n",
    "    }\n",
    "\n",
    "    # ‚úÖ Definindo os marcadores usados para cada classe\n",
    "    markers = (\"o\", \"^\")  # Classe 0: c√≠rculo, Classe 1: tri√¢ngulo\n",
    "\n",
    "    # ‚úÖ Plotando os pontos reais do conjunto de dados, separados por classe\n",
    "    for idx in (0, 1):  # Itera sobre as duas classes poss√≠veis: 0 e 1\n",
    "        plt.plot(\n",
    "            X[:, 0][y == idx],    # x-coordenadas dos pontos cuja classe real √© idx (primeira feature)\n",
    "            X[:, 1][y == idx],    # y-coordenadas dos pontos cuja classe real √© idx (segunda feature)\n",
    "            color=colors[cmap][idx],  # Cor associada √† classe idx, de acordo com o cmap selecionado\n",
    "            marker=markers[idx],      # Marcador espec√≠fico para a classe idx (ex.: 'o', '^', etc.)\n",
    "            linestyle=\"none\"          # Sem linhas conectando os pontos, apenas os marcadores isolados\n",
    "        )\n",
    "    # Resultado: os pontos reais s√£o sobrepostos ao gr√°fico, cada classe com uma cor e marcador distintos,\n",
    "    # facilitando a visualiza√ß√£o da correspond√™ncia entre regi√µes de decis√£o e dados reais.\n",
    "\n",
    "\n",
    "    # ‚úÖ Definindo os limites dos eixos conforme especificado\n",
    "    plt.axis(axes)\n",
    "\n",
    "    # ‚úÖ Rotulando o eixo x\n",
    "    plt.xlabel(r\"$x_1$\")  # r indica string raw ‚Üí √∫til para LaTeX\n",
    "\n",
    "    # ‚úÖ Rotulando o eixo y, mas com rota√ß√£o 0 (horizontal)\n",
    "    plt.ylabel(r\"$x_2$\", rotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812322d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b39f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.meshgrid(\n",
    "        np.linspace(1, 2, 3),  \n",
    "        np.linspace(2, 3, 3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb08854",
   "metadata": {},
   "source": [
    ">**Criando o Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2810ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Configurando a semente para reprodutibilidade\n",
    "np.random.seed(6)  # Garante que os mesmos n√∫meros aleat√≥rios sejam gerados sempre que o c√≥digo for executado\n",
    "\n",
    "# ‚úÖ Gerando um conjunto de dados bidimensional aleat√≥rio\n",
    "X_square = np.random.rand(100, 2) - 0.5  \n",
    "# Gera 100 amostras, cada uma com 2 dimens√µes (x, y)\n",
    "# np.random.rand gera valores no intervalo [0, 1), ent√£o subtra√≠mos 0.5 para centralizar em torno de 0\n",
    "# Resultado: pontos distribu√≠dos uniformemente no quadrado [-0.5, 0.5] x [-0.5, 0.5]\n",
    "\n",
    "# ‚úÖ Criando os r√≥tulos com base na posi√ß√£o horizontal\n",
    "y_square = (X_square[:, 0] > 0).astype(np.int64)  \n",
    "# Cria r√≥tulos bin√°rios: \n",
    "# Se a coordenada x do ponto for maior que 0 ‚Üí classe 1\n",
    "# Caso contr√°rio ‚Üí classe 0\n",
    "# .astype(np.int64) converte os valores booleanos (True/False) para inteiros (1/0)\n",
    "\n",
    "# ‚úÖ Definindo um √¢ngulo de rota√ß√£o de 45 graus\n",
    "angle = np.pi / 4  \n",
    "# np.pi representa o valor de œÄ (~3.14159...)\n",
    "# Dividido por 4 resulta em œÄ/4 radianos, equivalente a 45 graus\n",
    "\n",
    "# ‚úÖ Criando a matriz de rota√ß√£o em 2D\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(angle), -np.sin(angle)],  # Primeira linha: define a nova base para o eixo x ap√≥s rota√ß√£o\n",
    "    [np.sin(angle),  np.cos(angle)]   # Segunda linha: define a nova base para o eixo y\n",
    "])\n",
    "# F√≥rmula padr√£o da matriz de rota√ß√£o 2D no sentido anti-hor√°rio:\n",
    "# [[cosŒ∏, -sinŒ∏],\n",
    "#  [sinŒ∏,  cosŒ∏]]\n",
    "\n",
    "# ‚úÖ Aplicando a rota√ß√£o ao conjunto de dados\n",
    "X_rotated_square = X_square.dot(rotation_matrix)\n",
    "# Multiplica cada ponto da matriz X_square pela matriz de rota√ß√£o\n",
    "# Produto matricial ‚Üí transforma as coordenadas, rotacionando todos os pontos 45¬∞ no sentido anti-hor√°rio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4dc40",
   "metadata": {},
   "source": [
    ">**Criando o Gr√°fico:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc658f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Criando e treinando uma √°rvore de decis√£o no conjunto original\n",
    "tree_clf_square = DecisionTreeClassifier(random_state=42)  \n",
    "# Instancia o classificador √°rvore de decis√£o com uma semente fixa para reprodutibilidade\n",
    "tree_clf_square.fit(X_square, y_square)  \n",
    "# Treina o classificador nos dados originais\n",
    "\n",
    "# ‚úÖ Criando e treinando uma √°rvore de decis√£o no conjunto rotacionado\n",
    "tree_clf_rotated_square = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf_rotated_square.fit(X_rotated_square, y_square)\n",
    "# Treina o mesmo modelo, mas nos dados que foram rotacionados\n",
    "\n",
    "# ‚úÖ Criando dois subplots lado a lado para compara√ß√£o visual\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)  \n",
    "# ncols=2 ‚Üí duas colunas, figsize define o tamanho, sharey compartilha o eixo y\n",
    "\n",
    "# ‚úÖ Seleciona o primeiro eixo (subplot da esquerda)\n",
    "plt.sca(axes[0])  \n",
    "# Define que os comandos seguintes se aplicam a este eixo\n",
    "\n",
    "# ‚úÖ Plota a fronteira de decis√£o do modelo treinado no conjunto original\n",
    "plot_decision_boundary(\n",
    "    tree_clf_square,            # Modelo treinado\n",
    "    X_square,                   # Dados originais\n",
    "    y_square,                   # R√≥tulos\n",
    "    axes=[-0.7, 0.7, -0.7, 0.7],# Limites dos eixos: x e y de -0.7 a 0.7\n",
    "    cmap=\"Pastel1\"              # Colormap para colorir as classes\n",
    ")\n",
    "\n",
    "# ‚úÖ Seleciona o segundo eixo (subplot da direita)\n",
    "plt.sca(axes[1])\n",
    "\n",
    "# ‚úÖ Plota a fronteira de decis√£o do modelo treinado nos dados rotacionados\n",
    "plot_decision_boundary(\n",
    "    tree_clf_rotated_square,    # Modelo treinado nos dados rotacionados\n",
    "    X_rotated_square,           # Dados rotacionados\n",
    "    y_square,                   # R√≥tulos (mesmos do original)\n",
    "    axes=[-0.7, 0.7, -0.7, 0.7],\n",
    "    cmap=\"Pastel1\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Remove o r√≥tulo do eixo y para o segundo gr√°fico (opcional, est√©tica)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# ‚úÖ Fun√ß√£o para salvar a figura como arquivo\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"instabilidade_decision_tree.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# ‚úÖ Exibe os gr√°ficos na tela\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9beab",
   "metadata": {},
   "source": [
    "De modo geral, o principal problema das √Årvores de Decis√£o √© que elas s√£o muito sens√≠veis a pequenas varia√ß√µes nos dados de treinamento. Por exemplo, se retirarmos apenas a flor Iris versicolor mais larga do conjunto de treinamento (aquela com p√©talas de 4,8 cm de comprimento e 1,8 cm de largura) e treinar uma nova √Årvore de Decis√£o, poder√° obter o modelo representado na imagem abaixo. Ele ser√° muito diferente da √Årvore de Decis√£o anterior imagem de FRonteira de Decis√£o que plotamos anteriormente. Na verdade, como o algoritmo de treinamento usado pelo Scikit-Learn √© estoc√°stico, voc√™ pode obter modelos muito diferentes mesmo com os mesmos dados de treinamento (a menos que defina o hiperpar√¢metro *random_state*). Ex:\n",
    "\n",
    "```python\n",
    "# Sem random_state (resultado varia a cada execu√ß√£o)  \n",
    "modelo_instavel = DecisionTreeClassifier()  \n",
    "\n",
    "# Com random_state fixo (resultado sempre o mesmo)  \n",
    "modelo_reprodutivel = DecisionTreeClassifier(random_state=42)  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf_tweaked = DecisionTreeClassifier(max_depth=2, random_state=40)\n",
    "tree_clf_tweaked.fit(X_iris, y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88dfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Ajusta o tamanho da figura\n",
    "plt.figure(figsize=(8, 4))  \n",
    "# Cria uma figura de 8 polegadas de largura e 4 de altura\n",
    "\n",
    "# ‚úÖ Faz a predi√ß√£o em toda a malha de pontos do espa√ßo de atributos\n",
    "y_pred = tree_clf_tweaked.predict(X_iris_all).reshape(lengths.shape)  \n",
    "# X_iris_all: todos os pontos da malha gerada anteriormente (grid de petal length e width)\n",
    "# reshape para transformar de vetor em matriz com mesmo shape da malha\n",
    "\n",
    "# ‚úÖ Plota a regi√£o de decis√£o como um contorno preenchido\n",
    "plt.contourf(lengths, widths, y_pred, alpha=0.3, cmap=custom_cmap)  \n",
    "# lengths, widths: malha de pontos no espa√ßo das features\n",
    "# alpha=0.3 ‚Üí deixa a cor semi-transparente\n",
    "# cmap ‚Üí colormap customizado para cores das regi√µes\n",
    "\n",
    "# ‚úÖ Loop para plotar os pontos reais de cada classe\n",
    "for idx, (name, style) in enumerate(zip(iris.target_names, (\"yo\", \"bs\", \"g^\"))):\n",
    "    # idx: √≠ndice da classe (0,1,2); name: nome da esp√©cie; style: estilo do marcador\n",
    "    plt.plot(\n",
    "        X_iris[:, 0][y_iris == idx],  # Feature 1: comprimento da p√©tala\n",
    "        X_iris[:, 1][y_iris == idx],  # Feature 2: largura da p√©tala\n",
    "        style,                        # Estilo: 'yo' ‚Üí yellow circle, 'bs' ‚Üí blue square, 'g^' ‚Üí green triangle\n",
    "        label=f\"Iris {name}\"          # Legenda: nome da esp√©cie\n",
    "    )\n",
    "\n",
    "# ‚úÖ Obt√©m os thresholds (limiares) usados pela √°rvore para dividir os dados\n",
    "th0, th1 = tree_clf_tweaked.tree_.threshold[[0, 2]]  \n",
    "# Pega os thresholds dos n√≥s na profundidade 0 e 1\n",
    "# .tree_: estrutura interna da √°rvore de decis√£o\n",
    "# threshold: valores de corte usados nas divis√µes\n",
    "\n",
    "# ‚úÖ Plota a primeira linha de divis√£o (profundidade 0)\n",
    "plt.plot([0, 7.2], [th0, th0], \"k-\", linewidth=2)  \n",
    "# Linha preta cont√≠nua (\"k-\"), de espessura 2\n",
    "\n",
    "# ‚úÖ Plota a segunda linha de divis√£o (profundidade 1)\n",
    "plt.plot([0, 7.2], [th1, th1], \"k--\", linewidth=2)  \n",
    "# Linha preta tracejada (\"k--\"), tamb√©m de espessura 2\n",
    "\n",
    "# ‚úÖ Anota√ß√£o de texto indicando a profundidade da divis√£o\n",
    "plt.text(1.8, th0 + 0.05, \"Depth=0\", verticalalignment=\"bottom\", fontsize=15)\n",
    "# verticalalignment='bottom' ‚Üí texto alinhado pela base\n",
    "# fontsize define o tamanho da fonte\n",
    "\n",
    "plt.text(2.3, th1 + 0.05, \"Depth=1\", verticalalignment=\"bottom\", fontsize=13)\n",
    "\n",
    "# ‚úÖ Rotula os eixos\n",
    "plt.xlabel(\"Petal length (cm)\")\n",
    "plt.ylabel(\"Petal width (cm)\")\n",
    "\n",
    "# ‚úÖ Define os limites dos eixos\n",
    "plt.axis([0, 7.2, 0, 3])  \n",
    "# x: [0, 7.2], y: [0, 3]\n",
    "\n",
    "# ‚úÖ Adiciona a legenda (com nomes das classes)\n",
    "plt.legend()\n",
    "\n",
    "# ‚úÖ Fun√ß√£o para salvar a figura como arquivo\n",
    "# Define o caminho completo do arquivo\n",
    "output_path = os.path.join(output_dir, \"ivariacao_decision_tree.png\")\n",
    "\n",
    "# Salva a figura no caminho especificado\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# ‚úÖ Exibe a figura plotada\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55a80d",
   "metadata": {},
   "source": [
    "## ATIVIDADE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c13b2f",
   "metadata": {},
   "source": [
    "Como importar os dados:\n",
    "```python\n",
    "# Importa√ß√£o das bibliotecas\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Carregar o dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Criar DataFrame\n",
    "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y = pd.Series(wine.target, name='target')\n",
    "```\n",
    "\n",
    "> O Wine Dataset cont√©m 178 amostras de vinhos classificados em 3 tipos diferentes, com base em 13 caracter√≠sticas f√≠sico-qu√≠micas como teor alco√≥lico, acidez e intensidade da cor. √â um problema cl√°ssico de classifica√ß√£o multiclasse, amplamente utilizado para treinar e avaliar modelos como √°rvores de decis√£o.\n",
    "\n",
    "| Vari√°vel                            | Descri√ß√£o                                                                                                      |\n",
    "| ----------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n",
    "| **alcohol**                         | Teor alco√≥lico do vinho (%).                                                                                   |\n",
    "| **malic\\_acid**                     | Concentra√ß√£o de √°cido m√°lico.                                                                                  |\n",
    "| **ash**                             | Quantidade de cinzas (res√≠duo mineral).                                                                        |\n",
    "| **alcalinity\\_of\\_ash**             | Alcalinidade das cinzas.                                                                                       |\n",
    "| **magnesium**                       | Quantidade de magn√©sio.                                                                                        |\n",
    "| **total\\_phenols**                  | Total de fen√≥is, que influenciam sabor e textura.                                                              |\n",
    "| **flavanoids**                      | Subgrupo de fen√≥is, relacionados ao amargor e antioxidantes.                                                   |\n",
    "| **nonflavanoid\\_phenols**           | Fen√≥is n√£o flavonoides.                                                                                        |\n",
    "| **proanthocyanins**                 | Tipo espec√≠fico de tanino, afeta adstring√™ncia.                                                                |\n",
    "| **color\\_intensity**                | Intensidade da cor do vinho.                                                                                   |\n",
    "| **hue**                             | Tonalidade do vinho.                                                                                           |\n",
    "| **od280/od315\\_of\\_diluted\\_wines** | Absorb√¢ncia ‚Äî raz√£o entre leituras espectrofotom√©tricas em dois comprimentos de onda, relacionada √† qualidade. |\n",
    "| **proline**                         | Amino√°cido presente naturalmente, associado ao envelhecimento e maciez.                                        |\n",
    "\n",
    "##### Target (vari√°vel resposta):\n",
    "\n",
    "- **0**: Vinho da classe 1\n",
    "\n",
    "- **1**: Vinho da classe 2\n",
    "\n",
    "- **2**: Vinho da classe 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c84ed",
   "metadata": {},
   "source": [
    "**1) Sele√ß√£o de Vari√°veis (Feature Selection)**\n",
    "\n",
    "Escolha uma t√©cnica de sele√ß√£o de vari√°veis, como por exemplo:\n",
    "\n",
    "- An√°lise de correla√ß√£o (selecionar vari√°veis mais correlacionadas com o alvo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec0204",
   "metadata": {},
   "source": [
    "**2)  Dividir em Treino e Teste**\n",
    "\n",
    "Divida a base em:\n",
    "\n",
    "- 80% Treino\n",
    "\n",
    "- 20% Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7841298",
   "metadata": {},
   "source": [
    "**3) Constru√ß√£o do Modelo**\n",
    "\n",
    "Crie um modelo de √Årvore de Decis√£o para Classifica√ß√£o, utilizando:\n",
    "\n",
    "- Crit√©rio: \"Gini\" ou \"Entropy\".\n",
    "\n",
    "- Profundidade m√°xima (max_depth=3).\n",
    "\n",
    "- Treine e valide o modelo (Hold-Out ou K-Fold?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
